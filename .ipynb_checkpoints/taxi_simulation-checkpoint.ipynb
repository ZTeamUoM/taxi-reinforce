{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import simpy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import tensor_spec\n",
    "#from env.RideSimulator.Grid import Grid\n",
    "import tf_agents\n",
    "\n",
    "\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from RideSimulator.taxi_sim import run_simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register custom env\n",
    "import gym\n",
    "\n",
    "gym.envs.register(\n",
    "     id='taxi-v0',\n",
    "     entry_point='env.taxi:TaxiEnv',\n",
    "     max_episode_steps=1500,\n",
    "     kwargs={'state_dict':None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "\n",
    "num_iterations = 50 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 10  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 5  # @param {type:\"integer\"}\n",
    "eval_interval = 5  # @param {type:\"integer\"}action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load taxi env\n",
    "env_name = \"taxi-v0\"\n",
    "env = suite_gym.load(env_name)\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "reset = tf_env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent and policy\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    tf_env.observation_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "\n",
    "#random policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(),tf_env.action_spec())\n",
    "\n",
    "#agent policy\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "#replay buffer\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f98497b6400>\n"
     ]
    }
   ],
   "source": [
    "#create dataset and iterator\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npolicy.action(reset)\\n#tf_env.time_step_spec()\\nprint(reset)\\n#print(env.reset())\\n#print(ts.restart(tf.convert_to_tensor(np.array([0,0,0,0], dtype=np.int32), dtype=tf.float32)))\\nprint(\" \")\\nprint(ts.TimeStep(tf.constant([0]), tf.constant([0.0]), tf.constant([1.0]),tf.convert_to_tensor(np.array([[0,0,0,0]], dtype=np.int32), dtype=tf.float32)))\\n\\n#print(tensor_spec.to_array_spec(reset))\\n#encoder_func = tf_agents.utils.example_encoding.get_example_encoder(env.reset())\\n#encoder_func(env.reset())\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "policy.action(reset)\n",
    "#tf_env.time_step_spec()\n",
    "print(reset)\n",
    "#print(env.reset())\n",
    "#print(ts.restart(tf.convert_to_tensor(np.array([0,0,0,0], dtype=np.int32), dtype=tf.float32)))\n",
    "print(\" \")\n",
    "print(ts.TimeStep(tf.constant([0]), tf.constant([0.0]), tf.constant([1.0]),tf.convert_to_tensor(np.array([[0,0,0,0]], dtype=np.int32), dtype=tf.float32)))\n",
    "\n",
    "#print(tensor_spec.to_array_spec(reset))\n",
    "#encoder_func = tf_agents.utils.example_encoding.get_example_encoder(env.reset())\n",
    "#encoder_func(env.reset())\n",
    "\"\"\"\n",
    "\n",
    "#run_simulation(policy)\n",
    "#ts.termination(np.array([1,2,3,4], dtype=np.int32), reward=0.0)\n",
    "#ts.transition(np.array([1,2,3,4], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "12\n",
      "15\n",
      "10\n",
      "14\n",
      "1\n",
      "17\n",
      "11\n",
      "16\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "5\n",
      "9\n",
      "13\n",
      "4\n",
      "18\n",
      "0\n",
      "6\n",
      "19\n",
      "0 completed 13\n",
      "1 completed 13\n",
      "2 completed 11\n",
      "3 completed 15\n",
      "4 completed 18\n",
      "5 completed 10\n",
      "6 completed 12\n",
      "7 completed 10\n",
      "8 completed 11\n",
      "9 completed 9\n",
      "10 completed 10\n",
      "11 completed 13\n",
      "12 completed 12\n",
      "13 completed 18\n",
      "14 completed 11\n",
      "15 completed 12\n",
      "16 completed 11\n",
      "17 completed 15\n",
      "18 completed 13\n",
      "19 completed 13\n"
     ]
    }
   ],
   "source": [
    "#create a static environment for evaluation purposes\n",
    "\n",
    "#policy that always accepts\n",
    "class AcceptPolicy:\n",
    "  def __init__(self):\n",
    "    print(\"init\")\n",
    "\n",
    "  def action(self, obs):\n",
    "    return (tf.constant([1]))\n",
    "\n",
    "acceptPol = AcceptPolicy()\n",
    "\n",
    "eval_env = run_simulation(acceptPol)\n",
    "#print(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate a trained policy with respect to a pre-generated static environment\n",
    "def evaluatePolicy(policy, eval_env):\n",
    "    episode_reward = 0\n",
    "    for state_list in eval_env:\n",
    "        states = []\n",
    "        driver_reward = 0\n",
    "        \n",
    "        for i in range(len(state_list)):\n",
    "            state_tf = ts.TimeStep(tf.constant([1]), tf.constant(state_list[i][\"reward\"], dtype=tf.float32), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "            action = policy.action(state_tf)\n",
    "            #action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "            if (action[0].numpy() == 1):\n",
    "                reward = state_list[i][\"reward\"]\n",
    "            else:\n",
    "                reward = 0\n",
    "            print (reward)\n",
    "            driver_reward += reward\n",
    "        episode_reward += driver_reward\n",
    "        print(\"driver reward \", driver_reward)\n",
    "    print(\"total reward \", episode_reward)\n",
    "\n",
    "#evaluatePolicy(acceptPol, eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average return\n",
    "def compute_avg_return(policy, num_episodes=10):\n",
    "    total_reward = 0\n",
    "\n",
    "    for i in range (num_episodes):\n",
    "        #run one episode of simulation and record states\n",
    "        state_lists = run_simulation(policy)\n",
    "        episode_reward = 0\n",
    "        for state_list in state_lists:\n",
    "            states = []\n",
    "            driver_reward = 0\n",
    "\n",
    "            #convert states directly to tf timesteps\n",
    "            for i in range(len(state_list)):\n",
    "                state_tf = ts.TimeStep(tf.constant([1]), tf.constant(state_list[i][\"reward\"], dtype=tf.float32), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "                driver_reward += state_tf.reward\n",
    "            episode_reward += driver_reward\n",
    "        \n",
    "        #take average reward for all drivers in the episode\n",
    "        episode_reward = episode_reward / len(state_lists)\n",
    "        total_reward += episode_reward\n",
    "\n",
    "    avg_return = total_reward / num_episodes\n",
    "    print(avg_return)\n",
    "    return avg_return.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect trajectories\n",
    "\n",
    "def collect_data(num_iterations, policy, replay_buffer):\n",
    "    for i in range (num_iterations):\n",
    "        #run one episode of simulation and record states\n",
    "        state_lists = run_simulation(policy)\n",
    "        print(\"driver count : \", len(state_lists))\n",
    "        for state_list in state_lists:\n",
    "            states = []\n",
    "            actions = []\n",
    "\n",
    "            #convert states directly to tf timesteps\n",
    "            for i in range(len(state_list)):\n",
    "                #create time step\n",
    "                if i == 0:\n",
    "                    #state_tf = ts.restart(np.array(state_list[i][\"observation\"], dtype=np.float32))\n",
    "                    state_tf = ts.TimeStep(tf.constant([0]), tf.constant([3.0]), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "                    #print(\"first reward \", state_list[i][\"reward\"])\n",
    "                    #print (state_tf)\n",
    "                elif i < (len(state_list) - 1):\n",
    "                    #reward is taken fro (i-1) because it should be the reward from the already completed action (prev. action)\n",
    "                    state_tf = ts.TimeStep(tf.constant([1]), tf.constant(state_list[i-1][\"reward\"], dtype=tf.float32), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "                    #state_tf = ts.termination(np.array(state_list[i][\"observation\"], dtype=np.float32), reward=state_list[i][\"reward\"])\n",
    "                else:\n",
    "                    state_tf = ts.TimeStep(tf.constant([2]), tf.constant(state_list[i-1][\"reward\"], dtype=tf.float32), tf.constant([0.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "\n",
    "                #create action\n",
    "                \"\"\"if state_list[i][\"action\"] == 1:\n",
    "                    action = tf.constant([1], dtype=tf.int32)\n",
    "                else:\n",
    "                    action = tf.constant([0], dtype=tf.int32)\"\"\"\n",
    "                action = state_list[i][\"action\"]\n",
    "\n",
    "                #print (action)\n",
    "                states.append(state_tf)\n",
    "                actions.append(action)\n",
    "\n",
    "            for j in range(len(states)-1):\n",
    "                present_state = states[j]\n",
    "                next_state = states[j+1]\n",
    "                action = actions[j]\n",
    "                traj = trajectory.from_transition(present_state, action, next_state)\n",
    "                #print(action)\n",
    "                # Add trajectory to the replay buffer\n",
    "                replay_buffer.add_batch(traj)\n",
    "                #print(traj)\n",
    "\n",
    "        \"\"\"\n",
    "        #re-register environemnt with new states\n",
    "        env_name = 'taxi-v'+str(i)\n",
    "        gym.envs.register(\n",
    "             id=env_name,\n",
    "             entry_point='env.taxi:TaxiEnv',\n",
    "             max_episode_steps=1500,\n",
    "             kwargs={'state_dict':state_list},\n",
    "        )\n",
    "\n",
    "        #reload new env\n",
    "        env = suite_gym.load(env_name)\n",
    "        tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "        #reset tf env\n",
    "        time_step = tf_env.reset()\n",
    "\n",
    "        #loop through recorded steps\n",
    "        for step in state_dict:\n",
    "            present_state = tf_env.current_time_step()\n",
    "            action = step.action\n",
    "            new_state = tf_env.step(action)\n",
    "            traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "            replay_buffer.add_batch(traj)\n",
    "        \"\"\"\n",
    "        #print(replay_buffer)\n",
    "#collect_data(num_iterations, policy, replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n",
      "11\n",
      "13\n",
      "18\n",
      "17\n",
      "4\n",
      "3\n",
      "15\n",
      "10\n",
      "12\n",
      "7\n",
      "14\n",
      "0\n",
      "5\n",
      "16\n",
      "6\n",
      "2\n",
      "19\n",
      "8\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "18\n",
      "10\n",
      "5\n",
      "8\n",
      "16\n",
      "12\n",
      "2\n",
      "15\n",
      "6\n",
      "9\n",
      "3\n",
      "13\n",
      "7\n",
      "14\n",
      "1\n",
      "4\n",
      "19\n",
      "17\n",
      "11\n",
      "0\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "6\n",
      "19\n",
      "13\n",
      "17\n",
      "1\n",
      "2\n",
      "10\n",
      "15\n",
      "0\n",
      "8\n",
      "5\n",
      "3\n",
      "18\n",
      "14\n",
      "12\n",
      "16\n",
      "7\n",
      "9\n",
      "11\n",
      "4\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "7\n",
      "18\n",
      "0\n",
      "19\n",
      "9\n",
      "1\n",
      "12\n",
      "14\n",
      "2\n",
      "5\n",
      "3\n",
      "10\n",
      "16\n",
      "17\n",
      "13\n",
      "11\n",
      "6\n",
      "15\n",
      "8\n",
      "4\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "7\n",
      "6\n",
      "13\n",
      "11\n",
      "1\n",
      "15\n",
      "18\n",
      "8\n",
      "10\n",
      "5\n",
      "2\n",
      "9\n",
      "0\n",
      "17\n",
      "14\n",
      "3\n",
      "19\n",
      "16\n",
      "12\n",
      "4\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "3\n",
      "7\n",
      "0\n",
      "1\n",
      "18\n",
      "16\n",
      "15\n",
      "2\n",
      "17\n",
      "5\n",
      "13\n",
      "8\n",
      "14\n",
      "4\n",
      "6\n",
      "9\n",
      "12\n",
      "11\n",
      "10\n",
      "19\n",
      "0 completed 11\n",
      "1 completed 9\n",
      "2 completed 5\n",
      "3 completed 6\n",
      "4 completed 8\n",
      "5 completed 11\n",
      "6 completed 12\n",
      "7 completed 10\n",
      "8 completed 8\n",
      "9 completed 9\n",
      "10 completed 7\n",
      "11 completed 9\n",
      "12 completed 7\n",
      "13 completed 6\n",
      "14 completed 12\n",
      "15 completed 4\n",
      "16 completed 3\n",
      "17 completed 11\n",
      "18 completed 9\n",
      "19 completed 8\n",
      "driver count :  20\n",
      "13\n",
      "7\n",
      "14\n",
      "3\n",
      "19\n",
      "1\n",
      "5\n",
      "11\n",
      "18\n",
      "17\n",
      "8\n",
      "9\n",
      "16\n",
      "0\n",
      "10\n",
      "15\n",
      "2\n",
      "12\n",
      "6\n",
      "4\n",
      "0 completed 10\n",
      "1 completed 7\n",
      "2 completed 11\n",
      "3 completed 9\n",
      "4 completed 10\n",
      "5 completed 15\n",
      "6 completed 8\n",
      "7 completed 9\n",
      "8 completed 7\n",
      "9 completed 6\n",
      "10 completed 6\n",
      "11 completed 4\n",
      "12 completed 9\n",
      "13 completed 13\n",
      "14 completed 8\n",
      "15 completed 8\n",
      "16 completed 11\n",
      "17 completed 9\n",
      "18 completed 7\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "14\n",
      "1\n",
      "15\n",
      "5\n",
      "10\n",
      "2\n",
      "19\n",
      "13\n",
      "4\n",
      "12\n",
      "0\n",
      "17\n",
      "3\n",
      "6\n",
      "8\n",
      "9\n",
      "11\n",
      "18\n",
      "16\n",
      "7\n",
      "0 completed 7\n",
      "1 completed 4\n",
      "2 completed 10\n",
      "3 completed 14\n",
      "4 completed 4\n",
      "5 completed 5\n",
      "6 completed 6\n",
      "7 completed 11\n",
      "8 completed 14\n",
      "9 completed 4\n",
      "10 completed 5\n",
      "11 completed 11\n",
      "12 completed 10\n",
      "13 completed 8\n",
      "14 completed 7\n",
      "15 completed 10\n",
      "16 completed 15\n",
      "17 completed 10\n",
      "18 completed 9\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "14\n",
      "9\n",
      "4\n",
      "17\n",
      "3\n",
      "7\n",
      "6\n",
      "1\n",
      "5\n",
      "10\n",
      "18\n",
      "2\n",
      "0\n",
      "16\n",
      "12\n",
      "8\n",
      "19\n",
      "11\n",
      "13\n",
      "15\n",
      "0 completed 4\n",
      "1 completed 3\n",
      "2 completed 6\n",
      "3 completed 5\n",
      "4 completed 12\n",
      "5 completed 9\n",
      "6 completed 10\n",
      "7 completed 10\n",
      "8 completed 13\n",
      "9 completed 9\n",
      "10 completed 6\n",
      "11 completed 9\n",
      "12 completed 6\n",
      "13 completed 9\n",
      "14 completed 9\n",
      "15 completed 7\n",
      "16 completed 14\n",
      "17 completed 6\n",
      "18 completed 10\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "10\n",
      "11\n",
      "7\n",
      "15\n",
      "17\n",
      "3\n",
      "14\n",
      "19\n",
      "2\n",
      "6\n",
      "9\n",
      "1\n",
      "5\n",
      "13\n",
      "16\n",
      "0\n",
      "18\n",
      "12\n",
      "8\n",
      "4\n",
      "0 completed 11\n",
      "1 completed 11\n",
      "2 completed 7\n",
      "3 completed 10\n",
      "4 completed 7\n",
      "5 completed 10\n",
      "6 completed 8\n",
      "7 completed 6\n",
      "8 completed 8\n",
      "9 completed 2\n",
      "10 completed 11\n",
      "11 completed 4\n",
      "12 completed 4\n",
      "13 completed 8\n",
      "14 completed 6\n",
      "15 completed 7\n",
      "16 completed 7\n",
      "17 completed 13\n",
      "18 completed 10\n",
      "19 completed 11\n",
      "driver count :  20\n",
      "0\n",
      "5\n",
      "13\n",
      "1\n",
      "10\n",
      "2\n",
      "15\n",
      "17\n",
      "3\n",
      "8\n",
      "6\n",
      "12\n",
      "11\n",
      "19\n",
      "14\n",
      "4\n",
      "16\n",
      "18\n",
      "9\n",
      "7\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "0\n",
      "4\n",
      "12\n",
      "11\n",
      "2\n",
      "14\n",
      "7\n",
      "3\n",
      "13\n",
      "15\n",
      "10\n",
      "17\n",
      "16\n",
      "5\n",
      "9\n",
      "6\n",
      "8\n",
      "18\n",
      "19\n",
      "1\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "1\n",
      "2\n",
      "9\n",
      "14\n",
      "13\n",
      "4\n",
      "11\n",
      "16\n",
      "18\n",
      "7\n",
      "15\n",
      "6\n",
      "12\n",
      "0\n",
      "8\n",
      "17\n",
      "19\n",
      "10\n",
      "3\n",
      "5\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "16\n",
      "10\n",
      "9\n",
      "6\n",
      "15\n",
      "18\n",
      "4\n",
      "8\n",
      "19\n",
      "13\n",
      "5\n",
      "7\n",
      "12\n",
      "17\n",
      "14\n",
      "11\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "18\n",
      "5\n",
      "11\n",
      "16\n",
      "7\n",
      "15\n",
      "6\n",
      "17\n",
      "2\n",
      "0\n",
      "10\n",
      "12\n",
      "3\n",
      "14\n",
      "4\n",
      "9\n",
      "1\n",
      "13\n",
      "8\n",
      "19\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 5: Average Return = 0.0\n",
      "evaluation\n",
      "0\n",
      "19\n",
      "6\n",
      "3\n",
      "12\n",
      "4\n",
      "14\n",
      "15\n",
      "10\n",
      "16\n",
      "13\n",
      "17\n",
      "8\n",
      "1\n",
      "7\n",
      "18\n",
      "5\n",
      "9\n",
      "11\n",
      "2\n",
      "0 completed 6\n",
      "1 completed 6\n",
      "2 completed 7\n",
      "3 completed 13\n",
      "4 completed 11\n",
      "5 completed 9\n",
      "6 completed 8\n",
      "7 completed 3\n",
      "8 completed 6\n",
      "9 completed 7\n",
      "10 completed 8\n",
      "11 completed 10\n",
      "12 completed 5\n",
      "13 completed 7\n",
      "14 completed 7\n",
      "15 completed 10\n",
      "16 completed 8\n",
      "17 completed 8\n",
      "18 completed 8\n",
      "19 completed 5\n",
      "driver count :  20\n",
      "14\n",
      "18\n",
      "8\n",
      "4\n",
      "19\n",
      "13\n",
      "10\n",
      "12\n",
      "11\n",
      "1\n",
      "5\n",
      "7\n",
      "2\n",
      "0\n",
      "9\n",
      "17\n",
      "6\n",
      "16\n",
      "15\n",
      "3\n",
      "0 completed 5\n",
      "1 completed 6\n",
      "2 completed 9\n",
      "3 completed 8\n",
      "4 completed 7\n",
      "5 completed 11\n",
      "6 completed 5\n",
      "7 completed 4\n",
      "8 completed 7\n",
      "9 completed 7\n",
      "10 completed 11\n",
      "11 completed 12\n",
      "12 completed 11\n",
      "13 completed 8\n",
      "14 completed 8\n",
      "15 completed 5\n",
      "16 completed 6\n",
      "17 completed 9\n",
      "18 completed 9\n",
      "19 completed 13\n",
      "driver count :  20\n",
      "8\n",
      "1\n",
      "14\n",
      "15\n",
      "5\n",
      "7\n",
      "16\n",
      "6\n",
      "18\n",
      "19\n",
      "13\n",
      "17\n",
      "11\n",
      "2\n",
      "12\n",
      "0\n",
      "4\n",
      "10\n",
      "3\n",
      "9\n",
      "0 completed 9\n",
      "1 completed 12\n",
      "2 completed 2\n",
      "3 completed 10\n",
      "4 completed 7\n",
      "5 completed 7\n",
      "6 completed 7\n",
      "7 completed 7\n",
      "8 completed 14\n",
      "9 completed 11\n",
      "10 completed 8\n",
      "11 completed 5\n",
      "12 completed 8\n",
      "13 completed 7\n",
      "14 completed 8\n",
      "15 completed 8\n",
      "16 completed 12\n",
      "17 completed 6\n",
      "18 completed 11\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "5\n",
      "9\n",
      "6\n",
      "19\n",
      "13\n",
      "16\n",
      "8\n",
      "4\n",
      "14\n",
      "11\n",
      "3\n",
      "17\n",
      "12\n",
      "15\n",
      "2\n",
      "10\n",
      "7\n",
      "1\n",
      "0\n",
      "18\n",
      "0 completed 12\n",
      "1 completed 10\n",
      "2 completed 7\n",
      "3 completed 8\n",
      "4 completed 6\n",
      "5 completed 5\n",
      "6 completed 5\n",
      "7 completed 10\n",
      "8 completed 4\n",
      "9 completed 8\n",
      "10 completed 9\n",
      "11 completed 7\n",
      "12 completed 7\n",
      "13 completed 17\n",
      "14 completed 9\n",
      "15 completed 6\n",
      "16 completed 5\n",
      "17 completed 5\n",
      "18 completed 10\n",
      "19 completed 10\n",
      "driver count :  20\n",
      "14\n",
      "9\n",
      "18\n",
      "3\n",
      "6\n",
      "19\n",
      "5\n",
      "13\n",
      "4\n",
      "8\n",
      "0\n",
      "2\n",
      "10\n",
      "11\n",
      "17\n",
      "7\n",
      "1\n",
      "15\n",
      "12\n",
      "16\n",
      "0 completed 9\n",
      "1 completed 9\n",
      "2 completed 10\n",
      "3 completed 15\n",
      "4 completed 6\n",
      "5 completed 9\n",
      "6 completed 5\n",
      "7 completed 7\n",
      "8 completed 11\n",
      "9 completed 7\n",
      "10 completed 6\n",
      "11 completed 3\n",
      "12 completed 5\n",
      "13 completed 5\n",
      "14 completed 7\n",
      "15 completed 9\n",
      "16 completed 11\n",
      "17 completed 8\n",
      "18 completed 11\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "step = 10: loss = 2198.736083984375\n",
      "11\n",
      "13\n",
      "15\n",
      "9\n",
      "8\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "6\n",
      "14\n",
      "17\n",
      "12\n",
      "16\n",
      "18\n",
      "4\n",
      "1\n",
      "5\n",
      "10\n",
      "19\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "2\n",
      "16\n",
      "1\n",
      "18\n",
      "13\n",
      "0\n",
      "9\n",
      "14\n",
      "4\n",
      "8\n",
      "7\n",
      "19\n",
      "3\n",
      "6\n",
      "17\n",
      "12\n",
      "15\n",
      "11\n",
      "10\n",
      "5\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "12\n",
      "9\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "13\n",
      "8\n",
      "14\n",
      "17\n",
      "2\n",
      "18\n",
      "11\n",
      "0\n",
      "10\n",
      "7\n",
      "19\n",
      "15\n",
      "16\n",
      "1\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "7\n",
      "18\n",
      "2\n",
      "3\n",
      "17\n",
      "12\n",
      "10\n",
      "1\n",
      "16\n",
      "9\n",
      "13\n",
      "6\n",
      "4\n",
      "15\n",
      "19\n",
      "5\n",
      "8\n",
      "11\n",
      "0\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "14\n",
      "16\n",
      "8\n",
      "7\n",
      "9\n",
      "13\n",
      "11\n",
      "4\n",
      "2\n",
      "17\n",
      "1\n",
      "18\n",
      "0\n",
      "6\n",
      "3\n",
      "12\n",
      "19\n",
      "5\n",
      "15\n",
      "10\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 10: Average Return = 0.0\n",
      "evaluation\n",
      "4\n",
      "18\n",
      "12\n",
      "5\n",
      "19\n",
      "0\n",
      "16\n",
      "13\n",
      "8\n",
      "10\n",
      "1\n",
      "2\n",
      "11\n",
      "14\n",
      "9\n",
      "17\n",
      "7\n",
      "15\n",
      "3\n",
      "6\n",
      "0 completed 9\n",
      "1 completed 14\n",
      "2 completed 7\n",
      "3 completed 6\n",
      "4 completed 8\n",
      "5 completed 6\n",
      "6 completed 14\n",
      "7 completed 4\n",
      "8 completed 5\n",
      "9 completed 7\n",
      "10 completed 6\n",
      "11 completed 6\n",
      "12 completed 6\n",
      "13 completed 5\n",
      "14 completed 7\n",
      "15 completed 8\n",
      "16 completed 6\n",
      "17 completed 11\n",
      "18 completed 15\n",
      "19 completed 5\n",
      "driver count :  20\n",
      "7\n",
      "2\n",
      "14\n",
      "17\n",
      "4\n",
      "12\n",
      "6\n",
      "15\n",
      "9\n",
      "19\n",
      "16\n",
      "18\n",
      "5\n",
      "0\n",
      "8\n",
      "1\n",
      "10\n",
      "11\n",
      "3\n",
      "13\n",
      "0 completed 9\n",
      "1 completed 5\n",
      "2 completed 10\n",
      "3 completed 6\n",
      "4 completed 6\n",
      "5 completed 6\n",
      "6 completed 6\n",
      "7 completed 8\n",
      "8 completed 7\n",
      "9 completed 3\n",
      "10 completed 4\n",
      "11 completed 5\n",
      "12 completed 10\n",
      "13 completed 14\n",
      "14 completed 7\n",
      "15 completed 13\n",
      "16 completed 2\n",
      "17 completed 11\n",
      "18 completed 5\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "16\n",
      "5\n",
      "15\n",
      "17\n",
      "9\n",
      "19\n",
      "10\n",
      "14\n",
      "13\n",
      "0\n",
      "7\n",
      "12\n",
      "6\n",
      "3\n",
      "2\n",
      "18\n",
      "8\n",
      "11\n",
      "1\n",
      "4\n",
      "0 completed 6\n",
      "1 completed 17\n",
      "2 completed 9\n",
      "3 completed 15\n",
      "4 completed 12\n",
      "5 completed 6\n",
      "6 completed 9\n",
      "7 completed 6\n",
      "8 completed 6\n",
      "9 completed 5\n",
      "10 completed 9\n",
      "11 completed 10\n",
      "12 completed 3\n",
      "13 completed 5\n",
      "14 completed 6\n",
      "15 completed 6\n",
      "16 completed 11\n",
      "17 completed 14\n",
      "18 completed 7\n",
      "19 completed 13\n",
      "driver count :  20\n",
      "14\n",
      "4\n",
      "1\n",
      "9\n",
      "10\n",
      "11\n",
      "8\n",
      "7\n",
      "17\n",
      "12\n",
      "2\n",
      "19\n",
      "16\n",
      "18\n",
      "15\n",
      "5\n",
      "6\n",
      "0\n",
      "3\n",
      "13\n",
      "0 completed 8\n",
      "1 completed 6\n",
      "2 completed 6\n",
      "3 completed 7\n",
      "4 completed 7\n",
      "5 completed 8\n",
      "6 completed 11\n",
      "7 completed 13\n",
      "8 completed 7\n",
      "9 completed 7\n",
      "10 completed 9\n",
      "11 completed 8\n",
      "12 completed 9\n",
      "13 completed 7\n",
      "14 completed 12\n",
      "15 completed 6\n",
      "16 completed 9\n",
      "17 completed 10\n",
      "18 completed 6\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "5\n",
      "12\n",
      "18\n",
      "14\n",
      "13\n",
      "7\n",
      "9\n",
      "19\n",
      "15\n",
      "17\n",
      "1\n",
      "10\n",
      "0\n",
      "8\n",
      "11\n",
      "6\n",
      "16\n",
      "3\n",
      "4\n",
      "2\n",
      "0 completed 8\n",
      "1 completed 8\n",
      "2 completed 4\n",
      "3 completed 9\n",
      "4 completed 7\n",
      "5 completed 7\n",
      "6 completed 8\n",
      "7 completed 12\n",
      "8 completed 7\n",
      "9 completed 11\n",
      "10 completed 6\n",
      "11 completed 9\n",
      "12 completed 8\n",
      "13 completed 6\n",
      "14 completed 6\n",
      "15 completed 9\n",
      "16 completed 9\n",
      "17 completed 12\n",
      "18 completed 10\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "5\n",
      "9\n",
      "1\n",
      "15\n",
      "4\n",
      "18\n",
      "7\n",
      "17\n",
      "12\n",
      "0\n",
      "14\n",
      "2\n",
      "13\n",
      "3\n",
      "16\n",
      "6\n",
      "11\n",
      "10\n",
      "8\n",
      "19\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "9\n",
      "5\n",
      "11\n",
      "15\n",
      "7\n",
      "10\n",
      "19\n",
      "4\n",
      "3\n",
      "2\n",
      "8\n",
      "17\n",
      "14\n",
      "18\n",
      "12\n",
      "16\n",
      "0\n",
      "13\n",
      "6\n",
      "1\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "5\n",
      "7\n",
      "10\n",
      "16\n",
      "13\n",
      "6\n",
      "14\n",
      "2\n",
      "11\n",
      "4\n",
      "19\n",
      "8\n",
      "15\n",
      "17\n",
      "3\n",
      "9\n",
      "12\n",
      "0\n",
      "1\n",
      "18\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "12\n",
      "9\n",
      "6\n",
      "2\n",
      "13\n",
      "10\n",
      "17\n",
      "19\n",
      "11\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "7\n",
      "14\n",
      "8\n",
      "0\n",
      "15\n",
      "18\n",
      "16\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "11\n",
      "0\n",
      "19\n",
      "3\n",
      "17\n",
      "12\n",
      "6\n",
      "18\n",
      "5\n",
      "7\n",
      "15\n",
      "1\n",
      "16\n",
      "10\n",
      "4\n",
      "8\n",
      "2\n",
      "13\n",
      "9\n",
      "14\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 15: Average Return = 0.0\n",
      "evaluation\n",
      "6\n",
      "14\n",
      "2\n",
      "11\n",
      "0\n",
      "5\n",
      "7\n",
      "10\n",
      "9\n",
      "3\n",
      "4\n",
      "16\n",
      "12\n",
      "15\n",
      "13\n",
      "1\n",
      "17\n",
      "19\n",
      "18\n",
      "8\n",
      "0 completed 5\n",
      "1 completed 6\n",
      "2 completed 16\n",
      "3 completed 3\n",
      "4 completed 13\n",
      "5 completed 6\n",
      "6 completed 2\n",
      "7 completed 9\n",
      "8 completed 4\n",
      "9 completed 12\n",
      "10 completed 5\n",
      "11 completed 9\n",
      "12 completed 13\n",
      "13 completed 6\n",
      "14 completed 6\n",
      "15 completed 5\n",
      "16 completed 8\n",
      "17 completed 11\n",
      "18 completed 6\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "6\n",
      "18\n",
      "14\n",
      "5\n",
      "4\n",
      "10\n",
      "3\n",
      "17\n",
      "8\n",
      "1\n",
      "16\n",
      "7\n",
      "9\n",
      "2\n",
      "11\n",
      "0\n",
      "13\n",
      "15\n",
      "12\n",
      "19\n",
      "0 completed 5\n",
      "1 completed 7\n",
      "2 completed 6\n",
      "3 completed 8\n",
      "4 completed 7\n",
      "5 completed 12\n",
      "6 completed 7\n",
      "7 completed 9\n",
      "8 completed 5\n",
      "9 completed 10\n",
      "10 completed 5\n",
      "11 completed 6\n",
      "12 completed 8\n",
      "13 completed 8\n",
      "14 completed 7\n",
      "15 completed 9\n",
      "16 completed 8\n",
      "17 completed 6\n",
      "18 completed 7\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "18\n",
      "16\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "10\n",
      "11\n",
      "13\n",
      "14\n",
      "2\n",
      "0\n",
      "6\n",
      "15\n",
      "5\n",
      "17\n",
      "12\n",
      "8\n",
      "9\n",
      "19\n",
      "0 completed 4\n",
      "1 completed 8\n",
      "2 completed 3\n",
      "3 completed 10\n",
      "4 completed 5\n",
      "5 completed 8\n",
      "6 completed 10\n",
      "7 completed 8\n",
      "8 completed 10\n",
      "9 completed 8\n",
      "10 completed 10\n",
      "11 completed 5\n",
      "12 completed 9\n",
      "13 completed 11\n",
      "14 completed 6\n",
      "15 completed 13\n",
      "16 completed 8\n",
      "17 completed 9\n",
      "18 completed 6\n",
      "19 completed 9\n",
      "driver count :  20\n",
      "8\n",
      "2\n",
      "6\n",
      "19\n",
      "14\n",
      "1\n",
      "0\n",
      "15\n",
      "12\n",
      "11\n",
      "13\n",
      "5\n",
      "9\n",
      "16\n",
      "7\n",
      "17\n",
      "3\n",
      "4\n",
      "18\n",
      "10\n",
      "0 completed 7\n",
      "1 completed 9\n",
      "2 completed 8\n",
      "3 completed 7\n",
      "4 completed 5\n",
      "5 completed 5\n",
      "6 completed 8\n",
      "7 completed 10\n",
      "8 completed 10\n",
      "9 completed 10\n",
      "10 completed 5\n",
      "11 completed 9\n",
      "12 completed 6\n",
      "13 completed 11\n",
      "14 completed 6\n",
      "15 completed 5\n",
      "16 completed 8\n",
      "17 completed 8\n",
      "18 completed 9\n",
      "19 completed 8\n",
      "driver count :  20\n",
      "19\n",
      "13\n",
      "11\n",
      "15\n",
      "5\n",
      "9\n",
      "6\n",
      "4\n",
      "1\n",
      "3\n",
      "7\n",
      "0\n",
      "16\n",
      "14\n",
      "10\n",
      "8\n",
      "12\n",
      "18\n",
      "2\n",
      "17\n",
      "0 completed 6\n",
      "1 completed 4\n",
      "2 completed 8\n",
      "3 completed 5\n",
      "4 completed 6\n",
      "5 completed 4\n",
      "6 completed 7\n",
      "7 completed 10\n",
      "8 completed 10\n",
      "9 completed 6\n",
      "10 completed 11\n",
      "11 completed 9\n",
      "12 completed 7\n",
      "13 completed 13\n",
      "14 completed 8\n",
      "15 completed 9\n",
      "16 completed 5\n",
      "17 completed 9\n",
      "18 completed 5\n",
      "19 completed 8\n",
      "driver count :  20\n",
      "step = 20: loss = 705.1319580078125\n",
      "11\n",
      "15\n",
      "2\n",
      "10\n",
      "16\n",
      "12\n",
      "5\n",
      "4\n",
      "14\n",
      "6\n",
      "13\n",
      "19\n",
      "0\n",
      "18\n",
      "8\n",
      "17\n",
      "1\n",
      "9\n",
      "7\n",
      "3\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "16\n",
      "8\n",
      "19\n",
      "5\n",
      "9\n",
      "2\n",
      "18\n",
      "13\n",
      "12\n",
      "3\n",
      "14\n",
      "17\n",
      "4\n",
      "0\n",
      "15\n",
      "10\n",
      "6\n",
      "11\n",
      "1\n",
      "7\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "11\n",
      "17\n",
      "6\n",
      "9\n",
      "2\n",
      "12\n",
      "18\n",
      "0\n",
      "13\n",
      "14\n",
      "19\n",
      "7\n",
      "10\n",
      "3\n",
      "1\n",
      "8\n",
      "16\n",
      "15\n",
      "4\n",
      "5\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "12\n",
      "18\n",
      "8\n",
      "17\n",
      "14\n",
      "9\n",
      "4\n",
      "6\n",
      "10\n",
      "1\n",
      "15\n",
      "0\n",
      "2\n",
      "16\n",
      "13\n",
      "3\n",
      "7\n",
      "19\n",
      "5\n",
      "11\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "1\n",
      "14\n",
      "0\n",
      "19\n",
      "13\n",
      "8\n",
      "9\n",
      "3\n",
      "11\n",
      "18\n",
      "7\n",
      "5\n",
      "17\n",
      "2\n",
      "6\n",
      "12\n",
      "4\n",
      "16\n",
      "10\n",
      "15\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 20: Average Return = 0.0\n",
      "evaluation\n",
      "8\n",
      "6\n",
      "11\n",
      "1\n",
      "14\n",
      "19\n",
      "3\n",
      "12\n",
      "0\n",
      "7\n",
      "2\n",
      "15\n",
      "17\n",
      "16\n",
      "10\n",
      "4\n",
      "18\n",
      "9\n",
      "13\n",
      "5\n",
      "0 completed 10\n",
      "1 completed 7\n",
      "2 completed 5\n",
      "3 completed 7\n",
      "4 completed 10\n",
      "5 completed 16\n",
      "6 completed 4\n",
      "7 completed 8\n",
      "8 completed 9\n",
      "9 completed 10\n",
      "10 completed 9\n",
      "11 completed 8\n",
      "12 completed 4\n",
      "13 completed 10\n",
      "14 completed 6\n",
      "15 completed 12\n",
      "16 completed 10\n",
      "17 completed 10\n",
      "18 completed 4\n",
      "19 completed 8\n",
      "driver count :  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "19\n",
      "2\n",
      "1\n",
      "4\n",
      "18\n",
      "3\n",
      "5\n",
      "13\n",
      "0\n",
      "9\n",
      "8\n",
      "16\n",
      "12\n",
      "7\n",
      "14\n",
      "10\n",
      "17\n",
      "15\n",
      "6\n",
      "0 completed 9\n",
      "1 completed 8\n",
      "2 completed 7\n",
      "3 completed 7\n",
      "4 completed 14\n",
      "5 completed 4\n",
      "6 completed 8\n",
      "7 completed 8\n",
      "8 completed 9\n",
      "9 completed 2\n",
      "10 completed 7\n",
      "11 completed 9\n",
      "12 completed 8\n",
      "13 completed 4\n",
      "14 completed 5\n",
      "15 completed 9\n",
      "16 completed 13\n",
      "17 completed 14\n",
      "18 completed 4\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "13\n",
      "3\n",
      "5\n",
      "1\n",
      "12\n",
      "2\n",
      "10\n",
      "7\n",
      "0\n",
      "8\n",
      "6\n",
      "11\n",
      "15\n",
      "18\n",
      "9\n",
      "4\n",
      "16\n",
      "19\n",
      "17\n",
      "14\n",
      "0 completed 8\n",
      "1 completed 8\n",
      "2 completed 16\n",
      "3 completed 4\n",
      "4 completed 9\n",
      "5 completed 7\n",
      "6 completed 4\n",
      "7 completed 8\n",
      "8 completed 4\n",
      "9 completed 5\n",
      "10 completed 7\n",
      "11 completed 10\n",
      "12 completed 8\n",
      "13 completed 8\n",
      "14 completed 7\n",
      "15 completed 5\n",
      "16 completed 5\n",
      "17 completed 9\n",
      "18 completed 7\n",
      "19 completed 14\n",
      "driver count :  20\n",
      "5\n",
      "13\n",
      "4\n",
      "11\n",
      "15\n",
      "18\n",
      "12\n",
      "9\n",
      "17\n",
      "7\n",
      "1\n",
      "8\n",
      "2\n",
      "3\n",
      "0\n",
      "19\n",
      "14\n",
      "6\n",
      "10\n",
      "16\n",
      "0 completed 7\n",
      "1 completed 7\n",
      "2 completed 4\n",
      "3 completed 8\n",
      "4 completed 8\n",
      "5 completed 11\n",
      "6 completed 8\n",
      "7 completed 8\n",
      "8 completed 5\n",
      "9 completed 8\n",
      "10 completed 8\n",
      "11 completed 9\n",
      "12 completed 8\n",
      "13 completed 10\n",
      "14 completed 13\n",
      "15 completed 6\n",
      "16 completed 12\n",
      "17 completed 5\n",
      "18 completed 7\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "2\n",
      "12\n",
      "14\n",
      "13\n",
      "3\n",
      "5\n",
      "8\n",
      "10\n",
      "4\n",
      "17\n",
      "6\n",
      "19\n",
      "1\n",
      "11\n",
      "7\n",
      "9\n",
      "0\n",
      "16\n",
      "18\n",
      "15\n",
      "0 completed 5\n",
      "1 completed 6\n",
      "2 completed 9\n",
      "3 completed 6\n",
      "4 completed 4\n",
      "5 completed 9\n",
      "6 completed 8\n",
      "7 completed 7\n",
      "8 completed 8\n",
      "9 completed 5\n",
      "10 completed 11\n",
      "11 completed 10\n",
      "12 completed 11\n",
      "13 completed 6\n",
      "14 completed 11\n",
      "15 completed 14\n",
      "16 completed 10\n",
      "17 completed 8\n",
      "18 completed 7\n",
      "19 completed 5\n",
      "driver count :  20\n",
      "4\n",
      "17\n",
      "15\n",
      "8\n",
      "7\n",
      "18\n",
      "19\n",
      "16\n",
      "6\n",
      "5\n",
      "14\n",
      "0\n",
      "11\n",
      "13\n",
      "1\n",
      "3\n",
      "2\n",
      "12\n",
      "9\n",
      "10\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "5\n",
      "18\n",
      "7\n",
      "6\n",
      "14\n",
      "0\n",
      "9\n",
      "1\n",
      "15\n",
      "4\n",
      "2\n",
      "8\n",
      "13\n",
      "16\n",
      "19\n",
      "11\n",
      "3\n",
      "17\n",
      "12\n",
      "10\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "19\n",
      "13\n",
      "7\n",
      "6\n",
      "12\n",
      "9\n",
      "17\n",
      "11\n",
      "10\n",
      "18\n",
      "4\n",
      "5\n",
      "15\n",
      "14\n",
      "3\n",
      "16\n",
      "1\n",
      "8\n",
      "2\n",
      "0\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "0\n",
      "9\n",
      "1\n",
      "10\n",
      "18\n",
      "14\n",
      "19\n",
      "6\n",
      "15\n",
      "8\n",
      "4\n",
      "2\n",
      "7\n",
      "17\n",
      "5\n",
      "16\n",
      "3\n",
      "12\n",
      "13\n",
      "11\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "10\n",
      "11\n",
      "1\n",
      "0\n",
      "13\n",
      "8\n",
      "5\n",
      "17\n",
      "7\n",
      "4\n",
      "19\n",
      "12\n",
      "3\n",
      "16\n",
      "15\n",
      "2\n",
      "9\n",
      "6\n",
      "14\n",
      "18\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 25: Average Return = 0.0\n",
      "evaluation\n",
      "14\n",
      "7\n",
      "10\n",
      "18\n",
      "16\n",
      "9\n",
      "19\n",
      "5\n",
      "4\n",
      "8\n",
      "3\n",
      "2\n",
      "12\n",
      "17\n",
      "11\n",
      "6\n",
      "1\n",
      "0\n",
      "13\n",
      "15\n",
      "0 completed 3\n",
      "1 completed 6\n",
      "2 completed 6\n",
      "3 completed 12\n",
      "4 completed 7\n",
      "5 completed 8\n",
      "6 completed 9\n",
      "7 completed 8\n",
      "8 completed 4\n",
      "9 completed 10\n",
      "10 completed 13\n",
      "11 completed 5\n",
      "12 completed 6\n",
      "13 completed 7\n",
      "14 completed 7\n",
      "15 completed 9\n",
      "16 completed 8\n",
      "17 completed 6\n",
      "18 completed 7\n",
      "19 completed 5\n",
      "driver count :  20\n",
      "10\n",
      "11\n",
      "9\n",
      "18\n",
      "12\n",
      "13\n",
      "5\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "16\n",
      "17\n",
      "8\n",
      "19\n",
      "14\n",
      "15\n",
      "7\n",
      "1\n",
      "4\n",
      "0 completed 9\n",
      "1 completed 15\n",
      "2 completed 9\n",
      "3 completed 10\n",
      "4 completed 8\n",
      "5 completed 10\n",
      "6 completed 8\n",
      "7 completed 8\n",
      "8 completed 8\n",
      "9 completed 4\n",
      "10 completed 5\n",
      "11 completed 8\n",
      "12 completed 9\n",
      "13 completed 7\n",
      "14 completed 5\n",
      "15 completed 13\n",
      "16 completed 11\n",
      "17 completed 8\n",
      "18 completed 7\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "3\n",
      "4\n",
      "9\n",
      "0\n",
      "8\n",
      "7\n",
      "5\n",
      "12\n",
      "16\n",
      "18\n",
      "17\n",
      "10\n",
      "13\n",
      "19\n",
      "14\n",
      "1\n",
      "11\n",
      "6\n",
      "2\n",
      "15\n",
      "0 completed 7\n",
      "1 completed 8\n",
      "2 completed 12\n",
      "3 completed 9\n",
      "4 completed 10\n",
      "5 completed 11\n",
      "6 completed 9\n",
      "7 completed 8\n",
      "8 completed 7\n",
      "9 completed 10\n",
      "10 completed 8\n",
      "11 completed 5\n",
      "12 completed 3\n",
      "13 completed 4\n",
      "14 completed 6\n",
      "15 completed 8\n",
      "16 completed 5\n",
      "17 completed 6\n",
      "18 completed 8\n",
      "19 completed 12\n",
      "driver count :  20\n",
      "8\n",
      "10\n",
      "4\n",
      "11\n",
      "2\n",
      "1\n",
      "16\n",
      "5\n",
      "3\n",
      "13\n",
      "18\n",
      "19\n",
      "7\n",
      "9\n",
      "6\n",
      "0\n",
      "15\n",
      "14\n",
      "17\n",
      "12\n",
      "0 completed 11\n",
      "1 completed 6\n",
      "2 completed 13\n",
      "3 completed 12\n",
      "4 completed 11\n",
      "5 completed 11\n",
      "6 completed 8\n",
      "7 completed 9\n",
      "8 completed 9\n",
      "9 completed 13\n",
      "10 completed 9\n",
      "11 completed 5\n",
      "12 completed 7\n",
      "13 completed 8\n",
      "14 completed 4\n",
      "15 completed 7\n",
      "16 completed 6\n",
      "17 completed 7\n",
      "18 completed 7\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "14\n",
      "6\n",
      "7\n",
      "15\n",
      "8\n",
      "9\n",
      "4\n",
      "16\n",
      "17\n",
      "5\n",
      "18\n",
      "1\n",
      "12\n",
      "13\n",
      "3\n",
      "10\n",
      "19\n",
      "0\n",
      "11\n",
      "2\n",
      "0 completed 6\n",
      "1 completed 7\n",
      "2 completed 6\n",
      "3 completed 6\n",
      "4 completed 4\n",
      "5 completed 10\n",
      "6 completed 10\n",
      "7 completed 8\n",
      "8 completed 6\n",
      "9 completed 4\n",
      "10 completed 6\n",
      "11 completed 9\n",
      "12 completed 10\n",
      "13 completed 3\n",
      "14 completed 10\n",
      "15 completed 12\n",
      "16 completed 8\n",
      "17 completed 4\n",
      "18 completed 6\n",
      "19 completed 11\n",
      "driver count :  20\n",
      "step = 30: loss = 921.5778198242188\n",
      "1\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "10\n",
      "18\n",
      "11\n",
      "8\n",
      "13\n",
      "12\n",
      "7\n",
      "19\n",
      "15\n",
      "4\n",
      "9\n",
      "16\n",
      "17\n",
      "5\n",
      "14\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "0\n",
      "15\n",
      "2\n",
      "14\n",
      "8\n",
      "1\n",
      "4\n",
      "10\n",
      "3\n",
      "9\n",
      "5\n",
      "18\n",
      "6\n",
      "19\n",
      "7\n",
      "17\n",
      "13\n",
      "11\n",
      "16\n",
      "12\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "6\n",
      "3\n",
      "19\n",
      "13\n",
      "4\n",
      "14\n",
      "18\n",
      "9\n",
      "12\n",
      "10\n",
      "16\n",
      "17\n",
      "11\n",
      "5\n",
      "1\n",
      "2\n",
      "15\n",
      "7\n",
      "8\n",
      "0\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "18\n",
      "0\n",
      "3\n",
      "9\n",
      "13\n",
      "4\n",
      "12\n",
      "5\n",
      "1\n",
      "7\n",
      "15\n",
      "8\n",
      "10\n",
      "6\n",
      "17\n",
      "2\n",
      "16\n",
      "11\n",
      "19\n",
      "14\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "16\n",
      "4\n",
      "19\n",
      "18\n",
      "15\n",
      "17\n",
      "7\n",
      "5\n",
      "6\n",
      "2\n",
      "9\n",
      "3\n",
      "11\n",
      "13\n",
      "10\n",
      "1\n",
      "14\n",
      "8\n",
      "0\n",
      "12\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 30: Average Return = 0.0\n",
      "evaluation\n",
      "15\n",
      "9\n",
      "6\n",
      "13\n",
      "17\n",
      "12\n",
      "0\n",
      "10\n",
      "7\n",
      "11\n",
      "2\n",
      "16\n",
      "14\n",
      "4\n",
      "1\n",
      "8\n",
      "5\n",
      "3\n",
      "18\n",
      "19\n",
      "0 completed 5\n",
      "1 completed 12\n",
      "2 completed 13\n",
      "3 completed 8\n",
      "4 completed 14\n",
      "5 completed 8\n",
      "6 completed 3\n",
      "7 completed 8\n",
      "8 completed 4\n",
      "9 completed 0\n",
      "10 completed 7\n",
      "11 completed 8\n",
      "12 completed 4\n",
      "13 completed 3\n",
      "14 completed 13\n",
      "15 completed 13\n",
      "16 completed 9\n",
      "17 completed 11\n",
      "18 completed 6\n",
      "19 completed 9\n",
      "driver count :  20\n",
      "5\n",
      "16\n",
      "19\n",
      "10\n",
      "4\n",
      "0\n",
      "15\n",
      "7\n",
      "12\n",
      "3\n",
      "13\n",
      "2\n",
      "8\n",
      "17\n",
      "6\n",
      "18\n",
      "1\n",
      "11\n",
      "14\n",
      "9\n",
      "0 completed 9\n",
      "1 completed 11\n",
      "2 completed 6\n",
      "3 completed 9\n",
      "4 completed 9\n",
      "5 completed 9\n",
      "6 completed 9\n",
      "7 completed 6\n",
      "8 completed 9\n",
      "9 completed 11\n",
      "10 completed 7\n",
      "11 completed 10\n",
      "12 completed 7\n",
      "13 completed 11\n",
      "14 completed 8\n",
      "15 completed 7\n",
      "16 completed 13\n",
      "17 completed 3\n",
      "18 completed 6\n",
      "19 completed 2\n",
      "driver count :  20\n",
      "2\n",
      "1\n",
      "16\n",
      "19\n",
      "6\n",
      "5\n",
      "12\n",
      "7\n",
      "17\n",
      "13\n",
      "11\n",
      "8\n",
      "4\n",
      "15\n",
      "3\n",
      "0\n",
      "9\n",
      "10\n",
      "18\n",
      "14\n",
      "0 completed 12\n",
      "1 completed 7\n",
      "2 completed 3\n",
      "3 completed 5\n",
      "4 completed 10\n",
      "5 completed 8\n",
      "6 completed 4\n",
      "7 completed 9\n",
      "8 completed 4\n",
      "9 completed 7\n",
      "10 completed 7\n",
      "11 completed 8\n",
      "12 completed 8\n",
      "13 completed 7\n",
      "14 completed 6\n",
      "15 completed 8\n",
      "16 completed 7\n",
      "17 completed 6\n",
      "18 completed 5\n",
      "19 completed 10\n",
      "driver count :  20\n",
      "10\n",
      "15\n",
      "11\n",
      "6\n",
      "4\n",
      "13\n",
      "19\n",
      "3\n",
      "14\n",
      "8\n",
      "16\n",
      "12\n",
      "7\n",
      "0\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "17\n",
      "18\n",
      "0 completed 9\n",
      "1 completed 9\n",
      "2 completed 9\n",
      "3 completed 5\n",
      "4 completed 8\n",
      "5 completed 8\n",
      "6 completed 8\n",
      "7 completed 5\n",
      "8 completed 7\n",
      "9 completed 14\n",
      "10 completed 3\n",
      "11 completed 8\n",
      "12 completed 9\n",
      "13 completed 8\n",
      "14 completed 7\n",
      "15 completed 8\n",
      "16 completed 10\n",
      "17 completed 4\n",
      "18 completed 15\n",
      "19 completed 8\n",
      "driver count :  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "18\n",
      "9\n",
      "8\n",
      "3\n",
      "19\n",
      "13\n",
      "7\n",
      "12\n",
      "5\n",
      "2\n",
      "16\n",
      "17\n",
      "6\n",
      "11\n",
      "1\n",
      "10\n",
      "15\n",
      "14\n",
      "0 completed 3\n",
      "1 completed 5\n",
      "2 completed 11\n",
      "3 completed 6\n",
      "4 completed 6\n",
      "5 completed 9\n",
      "6 completed 5\n",
      "7 completed 3\n",
      "8 completed 11\n",
      "9 completed 13\n",
      "10 completed 7\n",
      "11 completed 5\n",
      "12 completed 12\n",
      "13 completed 8\n",
      "14 completed 14\n",
      "15 completed 7\n",
      "16 completed 8\n",
      "17 completed 10\n",
      "18 completed 14\n",
      "19 completed 10\n",
      "driver count :  20\n",
      "19\n",
      "15\n",
      "7\n",
      "10\n",
      "4\n",
      "11\n",
      "1\n",
      "8\n",
      "9\n",
      "17\n",
      "3\n",
      "13\n",
      "5\n",
      "6\n",
      "14\n",
      "2\n",
      "16\n",
      "0\n",
      "18\n",
      "12\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "6\n",
      "13\n",
      "4\n",
      "19\n",
      "7\n",
      "9\n",
      "0\n",
      "8\n",
      "5\n",
      "17\n",
      "15\n",
      "14\n",
      "10\n",
      "12\n",
      "3\n",
      "11\n",
      "1\n",
      "18\n",
      "2\n",
      "16\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "7\n",
      "0\n",
      "10\n",
      "14\n",
      "16\n",
      "6\n",
      "19\n",
      "9\n",
      "13\n",
      "15\n",
      "17\n",
      "5\n",
      "4\n",
      "1\n",
      "11\n",
      "3\n",
      "18\n",
      "2\n",
      "8\n",
      "12\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "7\n",
      "12\n",
      "5\n",
      "15\n",
      "10\n",
      "17\n",
      "9\n",
      "11\n",
      "3\n",
      "6\n",
      "14\n",
      "13\n",
      "8\n",
      "18\n",
      "16\n",
      "1\n",
      "4\n",
      "0\n",
      "19\n",
      "2\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "1\n",
      "11\n",
      "17\n",
      "13\n",
      "7\n",
      "12\n",
      "9\n",
      "6\n",
      "4\n",
      "14\n",
      "5\n",
      "10\n",
      "8\n",
      "3\n",
      "15\n",
      "0\n",
      "2\n",
      "16\n",
      "19\n",
      "18\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 35: Average Return = 0.0\n",
      "evaluation\n",
      "18\n",
      "12\n",
      "7\n",
      "8\n",
      "5\n",
      "10\n",
      "16\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "9\n",
      "14\n",
      "1\n",
      "6\n",
      "2\n",
      "19\n",
      "4\n",
      "0\n",
      "3\n",
      "0 completed 8\n",
      "1 completed 7\n",
      "2 completed 12\n",
      "3 completed 10\n",
      "4 completed 4\n",
      "5 completed 7\n",
      "6 completed 6\n",
      "7 completed 11\n",
      "8 completed 6\n",
      "9 completed 11\n",
      "10 completed 14\n",
      "11 completed 9\n",
      "12 completed 10\n",
      "13 completed 6\n",
      "14 completed 4\n",
      "15 completed 6\n",
      "16 completed 5\n",
      "17 completed 7\n",
      "18 completed 6\n",
      "19 completed 5\n",
      "driver count :  20\n",
      "12\n",
      "16\n",
      "7\n",
      "6\n",
      "15\n",
      "9\n",
      "8\n",
      "5\n",
      "11\n",
      "18\n",
      "1\n",
      "4\n",
      "17\n",
      "19\n",
      "10\n",
      "3\n",
      "2\n",
      "0\n",
      "13\n",
      "14\n",
      "0 completed 8\n",
      "1 completed 4\n",
      "2 completed 12\n",
      "3 completed 7\n",
      "4 completed 10\n",
      "5 completed 12\n",
      "6 completed 7\n",
      "7 completed 4\n",
      "8 completed 4\n",
      "9 completed 6\n",
      "10 completed 8\n",
      "11 completed 10\n",
      "12 completed 7\n",
      "13 completed 4\n",
      "14 completed 6\n",
      "15 completed 10\n",
      "16 completed 7\n",
      "17 completed 8\n",
      "18 completed 5\n",
      "19 completed 11\n",
      "driver count :  20\n",
      "4\n",
      "1\n",
      "18\n",
      "11\n",
      "2\n",
      "0\n",
      "12\n",
      "5\n",
      "7\n",
      "15\n",
      "19\n",
      "10\n",
      "16\n",
      "17\n",
      "13\n",
      "3\n",
      "9\n",
      "14\n",
      "6\n",
      "8\n",
      "0 completed 5\n",
      "1 completed 4\n",
      "2 completed 7\n",
      "3 completed 3\n",
      "4 completed 5\n",
      "5 completed 16\n",
      "6 completed 11\n",
      "7 completed 8\n",
      "8 completed 11\n",
      "9 completed 5\n",
      "10 completed 6\n",
      "11 completed 10\n",
      "12 completed 7\n",
      "13 completed 11\n",
      "14 completed 8\n",
      "15 completed 8\n",
      "16 completed 6\n",
      "17 completed 18\n",
      "18 completed 4\n",
      "19 completed 8\n",
      "driver count :  20\n",
      "0\n",
      "4\n",
      "11\n",
      "3\n",
      "7\n",
      "5\n",
      "16\n",
      "13\n",
      "10\n",
      "2\n",
      "1\n",
      "12\n",
      "14\n",
      "17\n",
      "6\n",
      "8\n",
      "15\n",
      "19\n",
      "18\n",
      "9\n",
      "0 completed 11\n",
      "1 completed 7\n",
      "2 completed 9\n",
      "3 completed 12\n",
      "4 completed 9\n",
      "5 completed 17\n",
      "6 completed 15\n",
      "7 completed 7\n",
      "8 completed 5\n",
      "9 completed 8\n",
      "10 completed 7\n",
      "11 completed 7\n",
      "12 completed 6\n",
      "13 completed 1\n",
      "14 completed 10\n",
      "15 completed 13\n",
      "16 completed 8\n",
      "17 completed 9\n",
      "18 completed 11\n",
      "19 completed 4\n",
      "driver count :  20\n",
      "17\n",
      "7\n",
      "15\n",
      "8\n",
      "6\n",
      "18\n",
      "11\n",
      "10\n",
      "14\n",
      "3\n",
      "12\n",
      "13\n",
      "2\n",
      "9\n",
      "19\n",
      "1\n",
      "0\n",
      "16\n",
      "4\n",
      "5\n",
      "0 completed 15\n",
      "1 completed 5\n",
      "2 completed 5\n",
      "3 completed 8\n",
      "4 completed 8\n",
      "5 completed 2\n",
      "6 completed 6\n",
      "7 completed 6\n",
      "8 completed 12\n",
      "9 completed 9\n",
      "10 completed 9\n",
      "11 completed 7\n",
      "12 completed 7\n",
      "13 completed 14\n",
      "14 completed 7\n",
      "15 completed 9\n",
      "16 completed 5\n",
      "17 completed 10\n",
      "18 completed 4\n",
      "19 completed 3\n",
      "driver count :  20\n",
      "step = 40: loss = 378.6615295410156\n",
      "17\n",
      "0\n",
      "1\n",
      "6\n",
      "12\n",
      "19\n",
      "10\n",
      "11\n",
      "14\n",
      "16\n",
      "18\n",
      "15\n",
      "3\n",
      "13\n",
      "7\n",
      "5\n",
      "4\n",
      "2\n",
      "9\n",
      "8\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "7\n",
      "14\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "15\n",
      "9\n",
      "2\n",
      "3\n",
      "11\n",
      "12\n",
      "16\n",
      "10\n",
      "13\n",
      "19\n",
      "4\n",
      "18\n",
      "17\n",
      "8\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "3\n",
      "2\n",
      "0\n",
      "11\n",
      "19\n",
      "13\n",
      "15\n",
      "6\n",
      "18\n",
      "12\n",
      "5\n",
      "1\n",
      "14\n",
      "7\n",
      "9\n",
      "17\n",
      "16\n",
      "10\n",
      "8\n",
      "4\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "10\n",
      "19\n",
      "13\n",
      "8\n",
      "17\n",
      "14\n",
      "3\n",
      "9\n",
      "15\n",
      "1\n",
      "16\n",
      "0\n",
      "4\n",
      "12\n",
      "11\n",
      "2\n",
      "7\n",
      "5\n",
      "6\n",
      "18\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "0\n",
      "11\n",
      "15\n",
      "9\n",
      "13\n",
      "5\n",
      "14\n",
      "4\n",
      "17\n",
      "7\n",
      "3\n",
      "6\n",
      "2\n",
      "12\n",
      "1\n",
      "18\n",
      "16\n",
      "19\n",
      "10\n",
      "8\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 40: Average Return = 0.0\n",
      "evaluation\n",
      "0\n",
      "6\n",
      "9\n",
      "18\n",
      "13\n",
      "17\n",
      "12\n",
      "4\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "16\n",
      "11\n",
      "7\n",
      "8\n",
      "19\n",
      "14\n",
      "5\n",
      "10\n",
      "0 completed 8\n",
      "1 completed 9\n",
      "2 completed 10\n",
      "3 completed 11\n",
      "4 completed 10\n",
      "5 completed 7\n",
      "6 completed 12\n",
      "7 completed 8\n",
      "8 completed 5\n",
      "9 completed 6\n",
      "10 completed 3\n",
      "11 completed 8\n",
      "12 completed 7\n",
      "13 completed 7\n",
      "14 completed 8\n",
      "15 completed 7\n",
      "16 completed 8\n",
      "17 completed 14\n",
      "18 completed 8\n",
      "19 completed 10\n",
      "driver count :  20\n",
      "18\n",
      "1\n",
      "17\n",
      "13\n",
      "10\n",
      "15\n",
      "8\n",
      "12\n",
      "2\n",
      "6\n",
      "0\n",
      "16\n",
      "14\n",
      "5\n",
      "3\n",
      "19\n",
      "4\n",
      "7\n",
      "11\n",
      "9\n",
      "0 completed 4\n",
      "1 completed 9\n",
      "2 completed 9\n",
      "3 completed 11\n",
      "4 completed 5\n",
      "5 completed 8\n",
      "6 completed 9\n",
      "7 completed 7\n",
      "8 completed 5\n",
      "9 completed 8\n",
      "10 completed 10\n",
      "11 completed 4\n",
      "12 completed 6\n",
      "13 completed 7\n",
      "14 completed 7\n",
      "15 completed 4\n",
      "16 completed 8\n",
      "17 completed 12\n",
      "18 completed 7\n",
      "19 completed 13\n",
      "driver count :  20\n",
      "10\n",
      "9\n",
      "16\n",
      "13\n",
      "7\n",
      "11\n",
      "5\n",
      "17\n",
      "0\n",
      "15\n",
      "1\n",
      "12\n",
      "18\n",
      "19\n",
      "4\n",
      "3\n",
      "14\n",
      "2\n",
      "8\n",
      "6\n",
      "0 completed 5\n",
      "1 completed 4\n",
      "2 completed 8\n",
      "3 completed 2\n",
      "4 completed 10\n",
      "5 completed 7\n",
      "6 completed 7\n",
      "7 completed 11\n",
      "8 completed 6\n",
      "9 completed 9\n",
      "10 completed 5\n",
      "11 completed 7\n",
      "12 completed 9\n",
      "13 completed 11\n",
      "14 completed 9\n",
      "15 completed 8\n",
      "16 completed 11\n",
      "17 completed 7\n",
      "18 completed 7\n",
      "19 completed 10\n",
      "driver count :  20\n",
      "14\n",
      "15\n",
      "7\n",
      "4\n",
      "8\n",
      "2\n",
      "3\n",
      "13\n",
      "12\n",
      "16\n",
      "9\n",
      "19\n",
      "17\n",
      "11\n",
      "0\n",
      "6\n",
      "1\n",
      "5\n",
      "18\n",
      "10\n",
      "0 completed 6\n",
      "1 completed 10\n",
      "2 completed 9\n",
      "3 completed 8\n",
      "4 completed 3\n",
      "5 completed 6\n",
      "6 completed 9\n",
      "7 completed 14\n",
      "8 completed 11\n",
      "9 completed 5\n",
      "10 completed 8\n",
      "11 completed 8\n",
      "12 completed 2\n",
      "13 completed 6\n",
      "14 completed 8\n",
      "15 completed 10\n",
      "16 completed 8\n",
      "17 completed 16\n",
      "18 completed 13\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "4\n",
      "0\n",
      "18\n",
      "12\n",
      "13\n",
      "11\n",
      "14\n",
      "6\n",
      "10\n",
      "19\n",
      "8\n",
      "2\n",
      "9\n",
      "1\n",
      "16\n",
      "5\n",
      "3\n",
      "15\n",
      "17\n",
      "7\n",
      "0 completed 10\n",
      "1 completed 7\n",
      "2 completed 9\n",
      "3 completed 10\n",
      "4 completed 8\n",
      "5 completed 6\n",
      "6 completed 7\n",
      "7 completed 6\n",
      "8 completed 9\n",
      "9 completed 10\n",
      "10 completed 12\n",
      "11 completed 8\n",
      "12 completed 11\n",
      "13 completed 5\n",
      "14 completed 10\n",
      "15 completed 7\n",
      "16 completed 5\n",
      "17 completed 5\n",
      "18 completed 9\n",
      "19 completed 6\n",
      "driver count :  20\n",
      "19\n",
      "2\n",
      "5\n",
      "0\n",
      "14\n",
      "10\n",
      "3\n",
      "13\n",
      "17\n",
      "16\n",
      "7\n",
      "18\n",
      "1\n",
      "11\n",
      "8\n",
      "4\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "1\n",
      "9\n",
      "5\n",
      "11\n",
      "4\n",
      "0\n",
      "10\n",
      "8\n",
      "6\n",
      "14\n",
      "2\n",
      "17\n",
      "3\n",
      "12\n",
      "19\n",
      "15\n",
      "7\n",
      "13\n",
      "18\n",
      "16\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "19\n",
      "7\n",
      "15\n",
      "1\n",
      "14\n",
      "5\n",
      "0\n",
      "3\n",
      "8\n",
      "12\n",
      "6\n",
      "16\n",
      "9\n",
      "2\n",
      "18\n",
      "13\n",
      "17\n",
      "10\n",
      "4\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "9\n",
      "19\n",
      "14\n",
      "18\n",
      "17\n",
      "1\n",
      "6\n",
      "11\n",
      "5\n",
      "3\n",
      "4\n",
      "12\n",
      "13\n",
      "2\n",
      "10\n",
      "7\n",
      "15\n",
      "0\n",
      "8\n",
      "16\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "5\n",
      "10\n",
      "17\n",
      "18\n",
      "4\n",
      "12\n",
      "13\n",
      "16\n",
      "1\n",
      "2\n",
      "3\n",
      "15\n",
      "7\n",
      "9\n",
      "0\n",
      "6\n",
      "19\n",
      "14\n",
      "11\n",
      "8\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 45: Average Return = 0.0\n",
      "evaluation\n",
      "12\n",
      "5\n",
      "14\n",
      "8\n",
      "7\n",
      "16\n",
      "2\n",
      "13\n",
      "10\n",
      "1\n",
      "4\n",
      "15\n",
      "17\n",
      "6\n",
      "18\n",
      "9\n",
      "0\n",
      "11\n",
      "3\n",
      "19\n",
      "0 completed 9\n",
      "1 completed 10\n",
      "2 completed 8\n",
      "3 completed 7\n",
      "4 completed 9\n",
      "5 completed 7\n",
      "6 completed 8\n",
      "7 completed 5\n",
      "8 completed 10\n",
      "9 completed 7\n",
      "10 completed 4\n",
      "11 completed 13\n",
      "12 completed 8\n",
      "13 completed 7\n",
      "14 completed 9\n",
      "15 completed 5\n",
      "16 completed 9\n",
      "17 completed 9\n",
      "18 completed 9\n",
      "19 completed 9\n",
      "driver count :  20\n",
      "2\n",
      "10\n",
      "7\n",
      "18\n",
      "1\n",
      "4\n",
      "9\n",
      "17\n",
      "8\n",
      "13\n",
      "12\n",
      "14\n",
      "19\n",
      "11\n",
      "5\n",
      "3\n",
      "0\n",
      "16\n",
      "15\n",
      "6\n",
      "0 completed 11\n",
      "1 completed 5\n",
      "2 completed 3\n",
      "3 completed 10\n",
      "4 completed 12\n",
      "5 completed 4\n",
      "6 completed 10\n",
      "7 completed 8\n",
      "8 completed 5\n",
      "9 completed 5\n",
      "10 completed 12\n",
      "11 completed 14\n",
      "12 completed 2\n",
      "13 completed 9\n",
      "14 completed 9\n",
      "15 completed 10\n",
      "16 completed 7\n",
      "17 completed 11\n",
      "18 completed 6\n",
      "19 completed 13\n",
      "driver count :  20\n",
      "16\n",
      "18\n",
      "13\n",
      "7\n",
      "10\n",
      "17\n",
      "8\n",
      "19\n",
      "15\n",
      "2\n",
      "4\n",
      "14\n",
      "0\n",
      "1\n",
      "12\n",
      "11\n",
      "6\n",
      "5\n",
      "9\n",
      "3\n",
      "0 completed 9\n",
      "1 completed 5\n",
      "2 completed 8\n",
      "3 completed 11\n",
      "4 completed 9\n",
      "5 completed 7\n",
      "6 completed 6\n",
      "7 completed 8\n",
      "8 completed 5\n",
      "9 completed 13\n",
      "10 completed 6\n",
      "11 completed 5\n",
      "12 completed 9\n",
      "13 completed 4\n",
      "14 completed 13\n",
      "15 completed 9\n",
      "16 completed 8\n",
      "17 completed 11\n",
      "18 completed 7\n",
      "19 completed 3\n",
      "driver count :  20\n",
      "19\n",
      "8\n",
      "14\n",
      "1\n",
      "11\n",
      "2\n",
      "13\n",
      "18\n",
      "9\n",
      "15\n",
      "17\n",
      "0\n",
      "10\n",
      "5\n",
      "7\n",
      "12\n",
      "4\n",
      "16\n",
      "3\n",
      "6\n",
      "0 completed 11\n",
      "1 completed 8\n",
      "2 completed 4\n",
      "3 completed 10\n",
      "4 completed 4\n",
      "5 completed 8\n",
      "6 completed 11\n",
      "7 completed 7\n",
      "8 completed 7\n",
      "9 completed 5\n",
      "10 completed 6\n",
      "11 completed 13\n",
      "12 completed 3\n",
      "13 completed 6\n",
      "14 completed 2\n",
      "15 completed 6\n",
      "16 completed 11\n",
      "17 completed 11\n",
      "18 completed 8\n",
      "19 completed 12\n",
      "driver count :  20\n",
      "1\n",
      "3\n",
      "11\n",
      "9\n",
      "19\n",
      "12\n",
      "13\n",
      "7\n",
      "16\n",
      "10\n",
      "15\n",
      "14\n",
      "8\n",
      "0\n",
      "17\n",
      "2\n",
      "6\n",
      "5\n",
      "4\n",
      "18\n",
      "0 completed 6\n",
      "1 completed 9\n",
      "2 completed 10\n",
      "3 completed 9\n",
      "4 completed 7\n",
      "5 completed 9\n",
      "6 completed 2\n",
      "7 completed 7\n",
      "8 completed 9\n",
      "9 completed 9\n",
      "10 completed 7\n",
      "11 completed 6\n",
      "12 completed 6\n",
      "13 completed 5\n",
      "14 completed 8\n",
      "15 completed 11\n",
      "16 completed 11\n",
      "17 completed 10\n",
      "18 completed 10\n",
      "19 completed 7\n",
      "driver count :  20\n",
      "step = 50: loss = 101.6266098022461\n",
      "7\n",
      "6\n",
      "16\n",
      "19\n",
      "0\n",
      "11\n",
      "8\n",
      "9\n",
      "3\n",
      "14\n",
      "17\n",
      "18\n",
      "12\n",
      "5\n",
      "4\n",
      "2\n",
      "1\n",
      "10\n",
      "13\n",
      "15\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "5\n",
      "3\n",
      "12\n",
      "13\n",
      "6\n",
      "14\n",
      "16\n",
      "8\n",
      "1\n",
      "4\n",
      "2\n",
      "15\n",
      "18\n",
      "7\n",
      "9\n",
      "10\n",
      "17\n",
      "11\n",
      "0\n",
      "19\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "13\n",
      "7\n",
      "11\n",
      "2\n",
      "8\n",
      "16\n",
      "10\n",
      "19\n",
      "18\n",
      "17\n",
      "9\n",
      "15\n",
      "4\n",
      "1\n",
      "3\n",
      "0\n",
      "5\n",
      "14\n",
      "6\n",
      "12\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "2\n",
      "18\n",
      "6\n",
      "19\n",
      "14\n",
      "3\n",
      "9\n",
      "8\n",
      "17\n",
      "15\n",
      "7\n",
      "16\n",
      "12\n",
      "11\n",
      "5\n",
      "1\n",
      "4\n",
      "10\n",
      "0\n",
      "13\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "19\n",
      "15\n",
      "7\n",
      "13\n",
      "1\n",
      "9\n",
      "12\n",
      "17\n",
      "3\n",
      "6\n",
      "14\n",
      "10\n",
      "18\n",
      "0\n",
      "5\n",
      "16\n",
      "8\n",
      "11\n",
      "4\n",
      "2\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "step = 50: Average Return = 0.0\n",
      "evaluation\n"
     ]
    }
   ],
   "source": [
    "#train agents\n",
    "\n",
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "lost_iterations = 0\n",
    "for _ in range(num_iterations):\n",
    "    try:\n",
    "        # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "        collect_data(collect_steps_per_iteration, collect_policy, replay_buffer)\n",
    "\n",
    "        # Sample a batch of data from the buffer and update the agent's network.\n",
    "        experience, unused_info = next(iterator)\n",
    "        train_loss = agent.train(experience).loss\n",
    "\n",
    "        step = agent.train_step_counter.numpy()\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            avg_return = compute_avg_return(eval_policy, num_eval_episodes)\n",
    "            print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "            returns.append(avg_return)\n",
    "            print(\"evaluation\")\n",
    "    \n",
    "    except IndexError:\n",
    "        lost_iterations += 1\n",
    "        print(\"skipping iteration due to driver error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize progress\n",
    "iterations = range(0, num_iterations +1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "#plt.ylim(top=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "1\n",
      "16\n",
      "12\n",
      "19\n",
      "10\n",
      "5\n",
      "15\n",
      "17\n",
      "9\n",
      "4\n",
      "7\n",
      "2\n",
      "18\n",
      "13\n",
      "8\n",
      "6\n",
      "11\n",
      "14\n",
      "0 completed 0\n",
      "1 completed 0\n",
      "2 completed 0\n",
      "3 completed 0\n",
      "4 completed 0\n",
      "5 completed 0\n",
      "6 completed 0\n",
      "7 completed 0\n",
      "8 completed 0\n",
      "9 completed 0\n",
      "10 completed 0\n",
      "11 completed 0\n",
      "12 completed 0\n",
      "13 completed 0\n",
      "14 completed 0\n",
      "15 completed 0\n",
      "16 completed 0\n",
      "17 completed 0\n",
      "18 completed 0\n",
      "19 completed 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'state': <RideSimulator.State.State at 0x7f97a470ed60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4726ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4723f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4719850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40774f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405bee20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840595a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984813cdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41acf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405ae20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485fb1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40554c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984822f790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840472760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483d77f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840310070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483d4130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484653d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482be580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aaca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a93a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [62, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281264f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810ad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030af40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ce50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fddf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402087c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e83d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400335e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400336d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e82b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ef10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a96d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a94f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205319a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481764c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f50d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e56a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9904281400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404167f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482a4f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984854ed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f35e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f32e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401057f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d21f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eacd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e40a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bebb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280431c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cdb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287166a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287324c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287195b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ffa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fe80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [64, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [62, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a02b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405589a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402377f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401349a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fef10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205364f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205366d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [64, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402abac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e59a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811deb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483629d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [62, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483620d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002ca00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811dd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829c910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002cdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a474a8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471ee50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47701f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d48b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b8460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401a42b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482e9550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984840abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840206550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482cb1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41f0100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984034fdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471e850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481fec70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485a45b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47444f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848244ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984810e2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017dd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840081430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a91c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840317640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e2190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480868b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402faa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e43d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030abe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c07c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281385e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405472b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402269d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a99d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e57f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f53a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f68b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f67f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f68e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401042b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b4e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404879d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aee20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010af70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eed00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f14c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010afa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d20a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ead60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bedc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e02b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079faf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207817f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ee50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287160a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872edc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a58e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d49a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a57c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402482b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481713d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281594f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281591f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d43d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c41f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014aa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012ba00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a49a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204feaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a38b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b69d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811dee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402666a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811dc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bebe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484beb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403636d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002ca30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402661c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4707460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47763d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470ab80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47107c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b88b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d45e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40705e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40709d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474a580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40580d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40681f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484fbc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482e58e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840415f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984819e250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984863a370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840310580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984845a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848521640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984057fee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848604040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a95e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e49a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e45b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d35e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030ac10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e84c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405479d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405473d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287411c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873efa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b66d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f99042811f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848526790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287798e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e06a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984056fcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848318eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404872b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840385e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840480fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984056f910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010ae50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fceb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f15e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eea90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cdd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207926d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207922e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e70a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287329d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871af70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481710a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816aaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a05b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287678e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ee20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287508e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401590a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401341c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401349d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c26a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a47c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c66a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a48b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b84c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c19a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022ad90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402660a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811da30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002ccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485525b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002cdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fc9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47760a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d07f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e433da60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404afa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848298040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470e4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47474c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984042ceb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984827ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d4880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bf4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848443610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47449a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984855ed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840271760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ea910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017d340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008dd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a92b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400777f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281172e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281359a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030ffd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405455e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d35b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d36a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402081f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a60d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e80a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e82e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ef40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205222b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404169d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f60d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404af5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287795b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840480100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281489a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f38b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401051c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eebe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eeac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f13a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280438b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400facd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e97c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ab50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207864c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d35e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287676d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287503d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405589d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014ae50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402342e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b85b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a35e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022aac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481067c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402667c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bed30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483622b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470a310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47036a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4723040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47603a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b68b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d42b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d41f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47708b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848190190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484ddf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401abc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481cb8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405cb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40680d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840269370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984852d7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41acb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40461c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017b610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840310d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984845a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840317610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ea850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848120400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281176a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984856e2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030ad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fde20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405474c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400333d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287461f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a58e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287727c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481765e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984025e760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e8d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485b3580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848421f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e00a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404850a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281480d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401056a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d29d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e47c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804da90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280566a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079ff70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e46a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207921f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872eeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871aaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d48e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d31c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287677c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ebb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008efd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287500d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400768e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405302b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400997c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402347c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401339d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d12b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fed30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a36a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402abf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e53a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b64c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027ccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811dc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483627c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002cc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d39d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470a5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4707820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47103d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47171f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b6280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d41c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40700d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b5bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47765e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287d0850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c98e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474a6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474aca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405cd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485cdf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402da670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984819e490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ae7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483d8e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828107d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023ceb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840597400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840361730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287c1550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984819ed30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aaeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281179a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281261f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811ffd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840081550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810ac10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281173d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fad00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d30a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e89a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405471f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400330d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400336a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405477f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287727f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ae20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205224f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816da90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fca90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e53d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e56d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404109d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404101c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401045b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404673d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f33d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f35b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d26a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f14f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bef40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e49a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bec70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404f3520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280578b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cdf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207922b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287327f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e93a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287198e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402487c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d48b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287671f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287506d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405588e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b82b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b84f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d15b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a34c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022aca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470acd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4747610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cb070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40770a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47761c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405ad90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470e670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41f0130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405cd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ce8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404b6670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402da730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4719e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483905e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828107a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982814a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984845a0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aabb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aab50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aad00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281269d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810abe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405450a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405494f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fab50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ca30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287419a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cffd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402261c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ab20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873eac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a93d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b60d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481769a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052aa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482a4fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404f39d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404802e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404672e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404679d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f30a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fad90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804dc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804dd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280432e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804da60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280406a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d31f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e90a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207818e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287327c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871aee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287191f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207864f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281593d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287675b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400966a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405587c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401593a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014acd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402378b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401339a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b83a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c12e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480856d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [62, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400294c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400294f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400298e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483624c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400291f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481503d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481061c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485520a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d39a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4707dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4703f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47104f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47763a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47175e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4707cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cb5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4726070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40777f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cbcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e433bc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840455e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474af40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984834a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41aca30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4717580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47100a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40586a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405ce80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40683d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848589dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ce910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403826d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480da160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848539460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003ebe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480c7d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848593c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848516130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480865e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840093670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810ab20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030ff40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a64c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287728e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816de20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481761f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404161c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401b7fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287797f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281481f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aeb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404871c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404858b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b4f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f34c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eedc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401086a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401087f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401080a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280404f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e41c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280576a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280574c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280400a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806ccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870db20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287328e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207811c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872faf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481718b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a06a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281599a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ea90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ef10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405305e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014ad30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400761c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022ac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e53d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480850a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403638b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d33a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829cf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4703f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471ea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47473d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47707c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47176d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47672b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d47c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cbe50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406de50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484a7850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474abe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418f7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418fb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418f760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471eb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401cedc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484aff10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480173d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400592b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984863aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e2940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079bbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848120190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400770a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281384c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fac10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405454c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405491c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405478b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405477c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400338b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287462b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001aaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a54c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a52e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816df70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b66a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481763d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e59d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404109a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404166d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984045c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401044f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aedc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eeeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e44c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fafd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804db50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280579a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e97f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280564c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079ffd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079feb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207816d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e75b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870dd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ad30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fa90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402485b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402482e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400765b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401351f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402372e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a48b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204feb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205360d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402aba30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c13d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b66a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480852b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a41f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480859a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811da90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403633a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4703f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fce50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47108e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47174c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475ce20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475ce80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47675b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b87c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40682b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287d0370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485fffa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474af70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c94f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40587c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40463d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40502e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840519700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848406670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485bc9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984808f160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017b430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401f6af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840472940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984819ff70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003edc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848516d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840317850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480861f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008db20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a90a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811faf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281350a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810acd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405495b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281382e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a64f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287460d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287465e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205225e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f54f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404101f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404161f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482a4a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404807c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e04f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984056fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404871f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404671f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404676a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e57c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eedf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d25b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401087c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281beb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804db20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806ce50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f19a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fad30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280563a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e41f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e45e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287322e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287197c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287323d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d45e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287676a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405304f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c48b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405586d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401352b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402536a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401335b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401347f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b87c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050faf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402371c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b64f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f97f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400409d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032abe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e59d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fce80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4747100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4717670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40556a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ab4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810e2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474ae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471e8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484068b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484c39a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404ab0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480170a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984833f3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482507f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840361d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840072e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840081190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281178e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281267f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fe50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810aa90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402082e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a66a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405478e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400339d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d51c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814ad00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f58b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052aaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052aca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287793a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401049a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281484f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e03d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b4880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e55b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401054f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404941f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f32b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d20d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f36a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404945b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804da30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e08e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e48e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207924f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287196a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816ac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a02e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008eb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400997f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401599d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401352e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c23d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b83d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204feee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480858b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481507f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032ad30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484beeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4707f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470ef40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47478e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47109a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47609a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470aee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fcbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d43d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b56d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485b5700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840313dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418f970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c90a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848440f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840269640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848231760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404af40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848235d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402024c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848580f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848434be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017d3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840081fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287c1a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806ca00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400774f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281383d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fadf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030ac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402faa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030abb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405476d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d57c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402266d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ab80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873eaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205315e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e53a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840476cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984025e7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984025ec40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848458a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404f3df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984056f820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404873a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fcd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404949d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d25e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eaf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eaa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401083d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804dc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280433a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806ca30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d36a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280562b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e42b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287164f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287169d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b54f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d42e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a53d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402489a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816afd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ee50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008eee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400960d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401592b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014ac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014ac10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401356d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401340d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c26d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b81f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a49a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fef40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c67f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c63d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022ad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c17f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811de20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481500a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bebb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002cd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4707370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4719700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fc370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b80a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b6220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030b580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984857e190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f99042dcc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40557f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848065700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984019e9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484774c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471e820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405ae50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017b730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480da3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287de8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848127e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840203c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984855ebb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828124b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aafa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848604100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848604f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480172e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e4e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829b430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008de20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984055b9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aaaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400777c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281352b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281173a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fac40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806ce20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a69d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405470d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c03a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287722b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402263a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b65e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052af40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052adf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e8400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287796d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840476460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404852e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fce80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d23d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280409a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d32b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e94c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e45b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870dbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870ddf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b57f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402483a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281597c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401598b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b85e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a46a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402abfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c19d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e58b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480856a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811ddf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811ddc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984002c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d30a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829ce20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4707af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fc760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470ac10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47762e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47762b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470af40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47760d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cb6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b6820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40706d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406be20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40709a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98497f05e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828131a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e32b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40586d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848281d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848477310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984869f8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848515bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848640eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401bdc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484efbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404e1880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848127d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848465d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ea310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480865b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a92e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400774c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984047ae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848422970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287c1a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e4e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fabe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281383a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405471c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d58b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287418b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287729a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402268b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402264f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a59d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ed60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a51c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404105b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481465e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404aff40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f990a7041f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848421610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485262e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281482e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aec40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404850d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e59a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404947c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eaeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eeb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbe80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804dbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d35e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cde50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b52b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871adf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287503a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400766d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405303d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405588b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401340a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b88e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c25b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401342e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014ba30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014be50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050fe20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fefa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205362b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a47c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022aee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027caf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e51f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481069d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bed60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485524f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829c7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4703a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4726130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47743a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470e040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47173d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47673d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406bf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402066d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484406d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ab280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474aee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41aca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47646d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482b7100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848589580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984840c760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401bdd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401f6e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984852db80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840317eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ea940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aaf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848604550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400773a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017d220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281260a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281386a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281381c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405497c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c04f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fda30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287412b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287720d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ab50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205221c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481467f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404168e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9904281340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b63d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984854e640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404f36d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287792e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404855b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984056ffa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e58e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e51c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010ad30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010aeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eaf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f13d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f19d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbdf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cde80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207929a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ad00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a56d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872efa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ffd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816a340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a01f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008eb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405304c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405308e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c44f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287502b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287504f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402340d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051caf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c20d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c29d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050ff10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a39a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b65e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [0, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811db50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481500d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032ad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403639d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032ad90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d3880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829c460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4703e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a46fc3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4707550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47769d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47748e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47174f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d42e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cba60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406deb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406dfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40467c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984050a430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b67f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4055d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40503d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405694c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405cf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480a2af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848131ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984840b1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482501f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848593670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023cf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984856e5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e5790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984047a4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079ba60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402083a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a65b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d3f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfe80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287466a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c07f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ad60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816db50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814aac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcdc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b67c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481764f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404104c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e54c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404164f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e51c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984842da30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287791c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404800a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485263d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b4520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840385610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f33a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404947f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eab20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280400d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804df70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280438e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204cd880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d38e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207811f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870da00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870daf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ae20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207860d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403641c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400968e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405309d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400769a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840253670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a48e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050f130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f92e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e50a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b68e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480858e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811da60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483624f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400407c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484bea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483626d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485526a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984829cc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470a0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4703bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47176a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4703be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d0df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d46d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cb640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47677c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cb850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470af70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406d550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47103a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848327e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41f00a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40584c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4046ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41d3640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40555b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a471eb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840202640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984869fee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405a5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848245370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401aba60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984819f0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828124a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984801a760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848066a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840072670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287c1250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008dee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079beb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806ccd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287faeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811fe80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848013a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402faca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d36d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ce20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c08e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d57f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205220a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a94c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816dc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a99a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b62b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205315b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481767c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848421f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404806a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481468b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984025e1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d26d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401083a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400faaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804dcd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280439d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280408e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280563d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872eac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287160d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870dbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207868b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287194c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b52e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cbfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400765e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400993d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400990d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051cd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012beb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401348e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840134220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fe700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c67c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c64f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d17f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d13d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f94c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402b6610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480850d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811dfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811de50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481507c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032ae20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403633d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f98401c0e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47745b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4703eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47600a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [67, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4717460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c9a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9849777fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cbc40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e43b85b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40703a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406ddc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47671c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4710310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848281880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404eab80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474aa90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984036c220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4058cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [2, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4050970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405adf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4747490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4719b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40502b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984840ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401faf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848245b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fa280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023ca30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483f2a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [65, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481db460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848521b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485214c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484227f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806c4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d5e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828126f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848516bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030fac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405451c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c02e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a67c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fdf10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840547d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287463a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001aa60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816db80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816dca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205310a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814af10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404100a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287796a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e05e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052afa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840480970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aec70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e08e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc6a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404940d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400e5610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281bef70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 5, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280434c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [67, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e49d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [63, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280570d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d33d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e41c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079fc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e05b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207924c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e76a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ee80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e47f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [0, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a1c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287195e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870d670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982870deb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481711f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d34c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403cb310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400963d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401350a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051ca60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401334f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c25e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [63, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984051c2b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d10d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982050ff40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205369d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c65b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d1df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a43a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027ca00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c68b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d8b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032acd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022abe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022acd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848552670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a4707bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47748b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4747340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4760d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [65, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764df0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475cd60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47601c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42d4040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cbb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40700a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47679a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4077a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40683a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a470ae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406df10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4070790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418fa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418f790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40469d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480ab520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40557c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40500a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405aac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401ce700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401f85b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281326d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984840c640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401bd310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483d7520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4764cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848244a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c5b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [63, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482be220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ea3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984821f3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b2e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a9430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984806cd30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828117cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281170d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481eaf70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a97c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fac70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828138760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030faf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840549730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840545f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054c4c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054ca00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c05e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e8ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840033520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401e86a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cf910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828741eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400cfa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287465b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c09a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001aa00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ee20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828746c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816dd00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816dfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fcaf0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984814a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b6a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205313d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98205316a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e57c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984842d130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982052a040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e02b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e07c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481ae700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840385460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401051f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401050a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eed30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840487850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840108310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ea100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281be9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f1100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 5, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eef10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fa6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280435e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [65, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281db310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204d3bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280569d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079f850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e9100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ed90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872ed00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820792820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ab20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828719610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287191c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840248ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848171fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840364a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008e880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008ea00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840096be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400992e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281596a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405585e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840530130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234ee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bbe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840099850>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840135a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840237be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d18e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014a9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fea90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c2760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c65e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a37c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b80d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204f9ca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fec40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cbb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027cc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811d100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 14, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848106a30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984027c310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040fd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [59, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984032a9d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840363d60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984811da00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484beac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482d38e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400403a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 38, 5, 40],\n",
       "   'reward': 0}],\n",
       " [{'state': <RideSimulator.State.State at 0x7f97a470afa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 43, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4774460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 25, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4723820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 58, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47766a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47645b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 37, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4770c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 9, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4767b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4703760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 24, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a475c130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42cbeb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 12, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c406b8e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 40, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c4068220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 7, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4776ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [50, 29, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a47175b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984043bf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e4329af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 4, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e42c9f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e418fb50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 33, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a474aac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [63, 47, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c40462b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404aa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 48, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41ac130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404a490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 18, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c405c3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97c404ae50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98482b7580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 21, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97e41b6490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 30, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404c2310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 17, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848640670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 34, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984843f820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 51, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401aec70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984023c460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 23, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848465190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 16, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984017dfa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 14, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848521460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 32, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984801a610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840310f40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 19, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 0, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287a99d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f97a4744430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 20, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984003e550>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984008d370>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 60, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840077b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403aa1f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281263a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 11, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982079b6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848013b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [16, 32, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828135760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 47, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982811f6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 15, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402e4340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810a0d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 27, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810ad90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 3, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030f0a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 5, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402fa430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 2, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402faa30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 58, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982810ac40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 40, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 18, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cfd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984054cf40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c0340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405490d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 39, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a6460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840208310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 43, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402089d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 12, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fd790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 22, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401fda60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405472e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 38, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405475b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 31, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984030a670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 28, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d5250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 13, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287464c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287720a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 26, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828772f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 33, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840226a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 30, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287726a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 16, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984001ae80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 23, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ea30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 24, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a5490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 35, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 36, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 14, 1, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a9b50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873ed30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984816d7c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204fc430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982873e160>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405b67f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 40, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820522c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 33, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531640>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 37, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176cd0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5f10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5e20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403e5790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848146730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 25, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f5c70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840416760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [18, 23, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404165e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f6820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 13, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820531c40>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 28, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848176fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403f60a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 8, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 17, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98404f38e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 29, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98480504c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 47, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401b7eb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287e0940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 48, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481aea60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828148820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840410220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828779430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 34, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 18, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840104970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 21, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400fc6d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 30, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 22, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 3, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010a730>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 38, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400f3a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 42, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840494190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281ee430>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [24, 26, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840467e80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [46, 31, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d21c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 32, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281d2490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [51, 49, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281eabe0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840105190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 27, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840485880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [15, 43, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401088e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 4, 2, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984010ab50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281e4490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d970>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828043220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [54, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281f16a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 9, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dbc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 6, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828040070>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [48, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982804d7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [63, 46, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e0610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 5, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e07c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 33, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98281dba90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 43, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280571c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 23, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cd90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98280430a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056d00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806cb20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 22, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [61, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828057bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [1, 57, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828056fa0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [21, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e91c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 15, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e4670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [10, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982806c790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 18, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820781580>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 26, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204e7a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716e50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 14, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 39, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828716190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 40, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732340>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [52, 30, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5b20>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a310>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 2, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820786a90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [13, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e250>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [41, 32, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a52e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 13, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403d4940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 19, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98403a5100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 29, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872e4f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 11, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98207b5100>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828732790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 8, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872fe50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [29, 16, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871ae50>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 24, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a0460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 31, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405a03a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 35, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982871a3a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 17, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 20, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f982872f940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [8, 21, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848033bb0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 38, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 48, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405d3a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 7, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 10, 3, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828750700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [9, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98287674c0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [3, 58, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98481712b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [17, 40, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828767130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [5, 42, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9828159790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400768b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 26, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 22, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840076700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98405c4460>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 32, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 3, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014adc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 25, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012b7f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [23, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984012bc10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [31, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840159220>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840234f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [44, 13, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402345b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [47, 23, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401355e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [11, 54, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402538b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98401336d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [39, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402373d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [28, 7, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840558280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 45, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402530d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 29, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840133760>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 41, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b8a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [57, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4a00>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [33, 17, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400a4700>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400c24f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [56, 28, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b280>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 6, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400b80a0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [37, 30, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bee0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [43, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9820536c10>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [49, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98204feca0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [36, 24, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400d14f0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [40, 4, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c6490>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 43, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014bb80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 12, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a4a60>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [30, 21, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402a3040>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [53, 44, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984014b3d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 51, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab400>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [25, 27, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1520>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [22, 15, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402abc70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 11, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a190>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [12, 8, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab820>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 35, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f984022a670>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 47, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98483e5d30>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [60, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402ab910>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [42, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085d90>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [20, 16, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402c1790>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [45, 33, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848085ac0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [4, 14, 4, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840029af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [19, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150940>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [32, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266f70>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 34, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040610>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [26, 24, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840266dc0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [6, 36, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402662e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [58, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98400403d0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [34, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9840040af0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [14, 27, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150880>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 53, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98402665e0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [35, 15, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98484be130>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [38, 28, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f98485528b0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [7, 16, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848362be0>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [27, 29, 5, 40],\n",
       "   'reward': 0},\n",
       "  {'state': <RideSimulator.State.State at 0x7f9848150b80>,\n",
       "   'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "   'observation': [55, 38, 5, 40],\n",
       "   'reward': 0}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run_simulation(eval_policy)\n",
    "evaluatePolicy(acceptPol, eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-68-ff0ae3fb21d8>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-ff0ae3fb21d8>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "reward results - \n",
    "random policy - around 9.5k\n",
    "learned policy - 14k\n",
    "always accept policy - 19.4k\n",
    "\"\"\"\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startup simulation\n",
    "\n",
    "def simpy_episode(rewards, steps, time_step, tf_env, policy):\n",
    "\n",
    "    TIME_MULTIPLIER = 50\n",
    "    DRIVER_COUNT = 1\n",
    "    TRIP_COUNT = 8000\n",
    "    RUN_TIME = 10000\n",
    "    INTERVAL = 20\n",
    "    # GRID_WIDTH = 3809\n",
    "    # GRID_HEIGHT = 2622\n",
    "    GRID_WIDTH = 60\n",
    "    GRID_HEIGHT = 40\n",
    "    HEX_AREA = 2.6\n",
    "\n",
    "    Env = simpy.Environment()\n",
    "    map_grid = Grid(env=Env, width=GRID_WIDTH, height=GRID_HEIGHT, interval=INTERVAL, num_drivers=DRIVER_COUNT,\n",
    "                    hex_area=HEX_AREA)\n",
    "\n",
    "    taxi_spots = map_grid.taxi_spots\n",
    "    driver_list = create_drivers(Env, DRIVER_COUNT, map_grid)\n",
    "    driver_pools = map_grid.driver_pools\n",
    "\n",
    "    run_simulation(TRIP_COUNT, RUN_TIME, DRIVER_COUNT, TIME_MULTIPLIER, map_grid, taxi_spots, driver_list, driver_pools, Env, rewards, steps, time_step, tf_env, policy)\n",
    "    t_count = 0\n",
    "    for dr in driver_list:\n",
    "        d_t_count = dr.total_trip_count\n",
    "        t_count += d_t_count\n",
    "        print(f\"{dr.id} completed {d_t_count}\")\n",
    "\n",
    "    print(f\"Total trip count: {t_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "var[0] = 2\n",
    "print (var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple episode run - atttempt 1\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    simpy_episode(rewards, step, time_step, tf_env, policy)\n",
    "\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple episode run - atttempt 2\n",
    "\n",
    "#time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    time_step = tf_env.reset()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    simpy_episode(rewards, step, time_step, tf_env, policy)\n",
    "\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple episode run template\n",
    "\"\"\"\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "  episode_reward = 0\n",
    "  episode_steps = 0\n",
    "  while not time_step.is_last():\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
