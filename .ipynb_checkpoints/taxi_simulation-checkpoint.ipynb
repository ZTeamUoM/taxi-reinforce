{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import simpy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import tensor_spec\n",
    "#from env.RideSimulator.Grid import Grid\n",
    "import tf_agents\n",
    "\n",
    "\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from RideSimulator.taxi_sim import run_simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register custom env\n",
    "import gym\n",
    "\n",
    "gym.envs.register(\n",
    "     id='taxi-v0',\n",
    "     entry_point='env.taxi:TaxiEnv',\n",
    "     max_episode_steps=1500,\n",
    "     kwargs={'state_dict':None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "\n",
    "num_iterations = 200 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load taxi env\n",
    "env_name = \"taxi-v0\"\n",
    "env = suite_gym.load(env_name)\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "reset = tf_env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent and policy\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    tf_env.observation_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "\n",
    "#random policy\n",
    "policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(),\n",
    "                                                tf_env.action_spec())\n",
    "\n",
    "\n",
    "#replay buffer\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f7f9805a490>\n"
     ]
    }
   ],
   "source": [
    "#create dataset and iterator\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npolicy.action(reset)\\n#tf_env.time_step_spec()\\nprint(reset)\\n#print(env.reset())\\n#print(ts.restart(tf.convert_to_tensor(np.array([0,0,0,0], dtype=np.int32), dtype=tf.float32)))\\nprint(\" \")\\nprint(ts.TimeStep(tf.constant([0]), tf.constant([0.0]), tf.constant([1.0]),tf.convert_to_tensor(np.array([[0,0,0,0]], dtype=np.int32), dtype=tf.float32)))\\n\\n#print(tensor_spec.to_array_spec(reset))\\n#encoder_func = tf_agents.utils.example_encoding.get_example_encoder(env.reset())\\n#encoder_func(env.reset())\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "policy.action(reset)\n",
    "#tf_env.time_step_spec()\n",
    "print(reset)\n",
    "#print(env.reset())\n",
    "#print(ts.restart(tf.convert_to_tensor(np.array([0,0,0,0], dtype=np.int32), dtype=tf.float32)))\n",
    "print(\" \")\n",
    "print(ts.TimeStep(tf.constant([0]), tf.constant([0.0]), tf.constant([1.0]),tf.convert_to_tensor(np.array([[0,0,0,0]], dtype=np.int32), dtype=tf.float32)))\n",
    "\n",
    "#print(tensor_spec.to_array_spec(reset))\n",
    "#encoder_func = tf_agents.utils.example_encoding.get_example_encoder(env.reset())\n",
    "#encoder_func(env.reset())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000, 40000, 60000, 60000]\n",
      "0 looking for driver at 0\n",
      "0 looking for driver at 50\n",
      "0 got 0 at 50\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[10.,  0.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 7 14] from [3 5]\n",
      "driver 0 location updated  to  [51  9]\n",
      "Trip distance: 44, time 60\n",
      "0 finished the trip and released driver 0 at 104 to pool 9\n",
      "Driver 0 finished trip\n",
      "1 looking for driver at 200\n",
      "1 looking for driver at 250\n",
      "1 got 0 at 250\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[12.,  1.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [45 19] from [51  9]\n",
      "driver 0 location updated  to  [14  6]\n",
      "Trip distance: 34, time 262\n",
      "1 finished the trip and released driver 0 at 296 to pool 3\n",
      "Driver 0 finished trip\n",
      "2 looking for driver at 400\n",
      "2 looking for driver at 450\n",
      "2 looking for driver at 500\n",
      "2 got 0 at 500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[44.,  2.,  0., 13.]], dtype=float32)>)\n",
      "2 looking for driver at 500\n",
      "3 looking for driver at 550\n",
      "2 looking for driver at 550\n",
      "3 looking for driver at 600\n",
      "2 looking for driver at 600\n",
      "3 got 0 at 600\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[20.,  2.,  0., 13.]], dtype=float32)>)\n",
      "3 looking for driver at 600\n",
      "3 looking for driver at 650\n",
      "2 looking for driver at 650\n",
      "3 looking for driver at 700\n",
      "2 looking for driver at 700\n",
      "3 looking for driver at 750\n",
      "2 looking for driver at 750\n",
      "3 looking for driver at 800\n",
      "2 looking for driver at 800\n",
      "4 looking for driver at 850\n",
      "3 looking for driver at 850\n",
      "2 looking for driver at 850\n",
      "5 looking for driver at 900\n",
      "4 looking for driver at 900\n",
      "3 looking for driver at 900\n",
      "2 looking for driver at 900\n",
      "6 looking for driver at 950\n",
      "5 looking for driver at 950\n",
      "4 looking for driver at 950\n",
      "3 looking for driver at 950\n",
      "2 looking for driver at 950\n",
      "5 got 0 at 950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[21.,  2.,  0., 13.]], dtype=float32)>)\n",
      "5 looking for driver at 950\n",
      "6 looking for driver at 1000\n",
      "5 looking for driver at 1000\n",
      "4 looking for driver at 1000\n",
      "3 looking for driver at 1000\n",
      "2 looking for driver at 1000\n",
      "4 got 0 at 1000\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[52.,  2.,  0., 13.]], dtype=float32)>)\n",
      "4 looking for driver at 1000\n",
      "6 looking for driver at 1050\n",
      "5 looking for driver at 1050\n",
      "4 looking for driver at 1050\n",
      "3 looking for driver at 1050\n",
      "2 looking for driver at 1050\n",
      "6 got 0 at 1050\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[34.,  2.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 8 39] from [14  6]\n",
      "driver 0 location updated  to  [37 11]\n",
      "Trip distance: 40, time 1084\n",
      "5 looking for driver at 1100\n",
      "4 looking for driver at 1100\n",
      "3 looking for driver at 1100\n",
      "2 looking for driver at 1100\n",
      "6 finished the trip and released driver 0 at 1124 to pool 7\n",
      "Driver 0 finished trip\n",
      "7 looking for driver at 1150\n",
      "5 looking for driver at 1150\n",
      "4 looking for driver at 1150\n",
      "3 looking for driver at 1150\n",
      "2 looking for driver at 1150\n",
      "8 looking for driver at 1200\n",
      "7 looking for driver at 1200\n",
      "5 looking for driver at 1200\n",
      "4 looking for driver at 1200\n",
      "3 looking for driver at 1200\n",
      "2 looking for driver at 1200\n",
      "7 got 0 at 1200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[21.,  3.,  0., 13.]], dtype=float32)>)\n",
      "7 looking for driver at 1200\n",
      "8 looking for driver at 1250\n",
      "7 looking for driver at 1250\n",
      "5 looking for driver at 1250\n",
      "4 looking for driver at 1250\n",
      "3 looking for driver at 1250\n",
      "2 looking for driver at 1250\n",
      "8 got 0 at 1250\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[16.,  3.,  0., 13.]], dtype=float32)>)\n",
      "8 looking for driver at 1250\n",
      "8 looking for driver at 1300\n",
      "7 looking for driver at 1300\n",
      "5 looking for driver at 1300\n",
      "4 looking for driver at 1300\n",
      "3 looking for driver at 1300\n",
      "2 looking for driver at 1300\n",
      "8 looking for driver at 1350\n",
      "7 looking for driver at 1350\n",
      "5 looking for driver at 1350\n",
      "4 looking for driver at 1350\n",
      "3 looking for driver at 1350\n",
      "2 looking for driver at 1350\n",
      "9 looking for driver at 1400\n",
      "8 looking for driver at 1400\n",
      "7 looking for driver at 1400\n",
      "5 looking for driver at 1400\n",
      "4 looking for driver at 1400\n",
      "3 looking for driver at 1400\n",
      "2 looking for driver at 1400\n",
      "9 looking for driver at 1450\n",
      "8 looking for driver at 1450\n",
      "7 looking for driver at 1450\n",
      "5 looking for driver at 1450\n",
      "4 looking for driver at 1450\n",
      "3 looking for driver at 1450\n",
      "2 was cancelled!\n",
      "9 looking for driver at 1500\n",
      "8 looking for driver at 1500\n",
      "7 looking for driver at 1500\n",
      "5 looking for driver at 1500\n",
      "4 looking for driver at 1500\n",
      "3 looking for driver at 1500\n",
      "9 got 0 at 1500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[21.,  3.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [18  1] from [37 11]\n",
      "driver 0 location updated  to  [21 13]\n",
      "Trip distance: 12, time 1521\n",
      "9 finished the trip and released driver 0 at 1533 to pool 4\n",
      "Driver 0 finished trip\n",
      "8 looking for driver at 1550\n",
      "7 looking for driver at 1550\n",
      "5 looking for driver at 1550\n",
      "4 looking for driver at 1550\n",
      "3 looking for driver at 1550\n",
      "8 looking for driver at 1600\n",
      "7 looking for driver at 1600\n",
      "5 looking for driver at 1600\n",
      "4 looking for driver at 1600\n",
      "3 was cancelled!\n",
      "8 looking for driver at 1650\n",
      "7 looking for driver at 1650\n",
      "5 looking for driver at 1650\n",
      "4 looking for driver at 1650\n",
      "10 looking for driver at 1700\n",
      "8 looking for driver at 1700\n",
      "7 looking for driver at 1700\n",
      "5 looking for driver at 1700\n",
      "4 looking for driver at 1700\n",
      "10 looking for driver at 1750\n",
      "8 looking for driver at 1750\n",
      "7 looking for driver at 1750\n",
      "5 looking for driver at 1750\n",
      "4 looking for driver at 1750\n",
      "10 got 0 at 1750\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[13.,  4.,  0., 13.]], dtype=float32)>)\n",
      "10 looking for driver at 1750\n",
      "10 looking for driver at 1800\n",
      "8 looking for driver at 1800\n",
      "7 looking for driver at 1800\n",
      "5 looking for driver at 1800\n",
      "4 looking for driver at 1800\n",
      "10 looking for driver at 1850\n",
      "8 looking for driver at 1850\n",
      "7 looking for driver at 1850\n",
      "5 looking for driver at 1850\n",
      "4 looking for driver at 1850\n",
      "10 looking for driver at 1900\n",
      "8 looking for driver at 1900\n",
      "7 looking for driver at 1900\n",
      "5 looking for driver at 1900\n",
      "4 was cancelled!\n",
      "11 looking for driver at 1950\n",
      "10 looking for driver at 1950\n",
      "8 looking for driver at 1950\n",
      "7 looking for driver at 1950\n",
      "5 was cancelled!\n",
      "11 looking for driver at 2000\n",
      "10 looking for driver at 2000\n",
      "8 looking for driver at 2000\n",
      "7 looking for driver at 2000\n",
      "11 got 0 at 2000\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[17.,  4.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [32 26] from [21 13]\n",
      "driver 0 location updated  to  [43 23]\n",
      "Trip distance: 11, time 2017\n",
      "11 finished the trip and released driver 0 at 2028 to pool 7\n",
      "Driver 0 finished trip\n",
      "12 looking for driver at 2050\n",
      "10 looking for driver at 2050\n",
      "8 looking for driver at 2050\n",
      "7 looking for driver at 2050\n",
      "12 looking for driver at 2100\n",
      "10 looking for driver at 2100\n",
      "8 looking for driver at 2100\n",
      "7 looking for driver at 2100\n",
      "12 looking for driver at 2150\n",
      "10 looking for driver at 2150\n",
      "8 looking for driver at 2150\n",
      "7 looking for driver at 2150\n",
      "12 got 0 at 2150\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[42.,  5.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 2 34] from [43 23]\n",
      "driver 0 location updated  to  [43 28]\n",
      "Trip distance: 41, time 2192\n",
      "10 looking for driver at 2200\n",
      "8 looking for driver at 2200\n",
      "7 was cancelled!\n",
      "12 finished the trip and released driver 0 at 2233 to pool 7\n",
      "Driver 0 finished trip\n",
      "10 looking for driver at 2250\n",
      "8 was cancelled!\n",
      "13 looking for driver at 2300\n",
      "10 looking for driver at 2300\n",
      "13 looking for driver at 2350\n",
      "10 looking for driver at 2350\n",
      "13 got 0 at 2350\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[10.,  6.,  0., 13.]], dtype=float32)>)\n",
      "13 looking for driver at 2350\n",
      "13 looking for driver at 2400\n",
      "10 looking for driver at 2400\n",
      "13 looking for driver at 2450\n",
      "10 looking for driver at 2450\n",
      "14 looking for driver at 2500\n",
      "13 looking for driver at 2500\n",
      "10 looking for driver at 2500\n",
      "14 looking for driver at 2550\n",
      "13 looking for driver at 2550\n",
      "10 looking for driver at 2550\n",
      "14 got 0 at 2550\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[17.,  6.,  0., 13.]], dtype=float32)>)\n",
      "14 looking for driver at 2550\n",
      "14 looking for driver at 2600\n",
      "13 looking for driver at 2600\n",
      "10 looking for driver at 2600\n",
      "14 looking for driver at 2650\n",
      "13 looking for driver at 2650\n",
      "10 looking for driver at 2650\n",
      "14 looking for driver at 2700\n",
      "13 looking for driver at 2700\n",
      "10 looking for driver at 2700\n",
      "14 looking for driver at 2750\n",
      "13 looking for driver at 2750\n",
      "10 was cancelled!\n",
      "15 looking for driver at 2800\n",
      "14 looking for driver at 2800\n",
      "13 looking for driver at 2800\n",
      "16 looking for driver at 2850\n",
      "15 looking for driver at 2850\n",
      "14 looking for driver at 2850\n",
      "13 looking for driver at 2850\n",
      "15 got 0 at 2850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[12.,  6.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [33 35] from [43 28]\n",
      "driver 0 location updated  to  [ 9 31]\n",
      "Trip distance: 24, time 2862\n",
      "15 finished the trip and released driver 0 at 2886 to pool 2\n",
      "Driver 0 finished trip\n",
      "17 looking for driver at 2900\n",
      "16 looking for driver at 2900\n",
      "14 looking for driver at 2900\n",
      "13 looking for driver at 2900\n",
      "16 got 0 at 2900\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 8.,  7.,  0., 13.]], dtype=float32)>)\n",
      "16 looking for driver at 2900\n",
      "17 looking for driver at 2950\n",
      "16 looking for driver at 2950\n",
      "14 looking for driver at 2950\n",
      "13 looking for driver at 2950\n",
      "17 looking for driver at 3000\n",
      "16 looking for driver at 3000\n",
      "14 looking for driver at 3000\n",
      "13 looking for driver at 3000\n",
      "17 looking for driver at 3050\n",
      "16 looking for driver at 3050\n",
      "14 looking for driver at 3050\n",
      "13 looking for driver at 3050\n",
      "17 looking for driver at 3100\n",
      "16 looking for driver at 3100\n",
      "14 looking for driver at 3100\n",
      "13 looking for driver at 3100\n",
      "17 got 0 at 3100\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[46.,  7.,  0., 13.]], dtype=float32)>)\n",
      "17 looking for driver at 3100\n",
      "18 looking for driver at 3150\n",
      "17 looking for driver at 3150\n",
      "16 looking for driver at 3150\n",
      "14 looking for driver at 3150\n",
      "13 looking for driver at 3150\n",
      "18 looking for driver at 3200\n",
      "17 looking for driver at 3200\n",
      "16 looking for driver at 3200\n",
      "14 looking for driver at 3200\n",
      "13 looking for driver at 3200\n",
      "18 looking for driver at 3250\n",
      "17 looking for driver at 3250\n",
      "16 looking for driver at 3250\n",
      "14 looking for driver at 3250\n",
      "13 looking for driver at 3250\n",
      "18 looking for driver at 3300\n",
      "17 looking for driver at 3300\n",
      "16 looking for driver at 3300\n",
      "14 looking for driver at 3300\n",
      "13 looking for driver at 3300\n",
      "18 got 0 at 3300\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[44.,  7.,  0., 13.]], dtype=float32)>)\n",
      "18 looking for driver at 3300\n",
      "19 looking for driver at 3350\n",
      "18 looking for driver at 3350\n",
      "17 looking for driver at 3350\n",
      "16 looking for driver at 3350\n",
      "14 looking for driver at 3350\n",
      "13 was cancelled!\n",
      "19 looking for driver at 3400\n",
      "18 looking for driver at 3400\n",
      "17 looking for driver at 3400\n",
      "16 looking for driver at 3400\n",
      "14 looking for driver at 3400\n",
      "19 got 0 at 3400\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[14.,  7.,  0., 13.]], dtype=float32)>)\n",
      "19 looking for driver at 3400\n",
      "19 looking for driver at 3450\n",
      "18 looking for driver at 3450\n",
      "17 looking for driver at 3450\n",
      "16 looking for driver at 3450\n",
      "14 looking for driver at 3450\n",
      "20 looking for driver at 3500\n",
      "19 looking for driver at 3500\n",
      "18 looking for driver at 3500\n",
      "17 looking for driver at 3500\n",
      "16 looking for driver at 3500\n",
      "14 looking for driver at 3500\n",
      "20 looking for driver at 3550\n",
      "19 looking for driver at 3550\n",
      "18 looking for driver at 3550\n",
      "17 looking for driver at 3550\n",
      "16 looking for driver at 3550\n",
      "14 was cancelled!\n",
      "20 looking for driver at 3600\n",
      "19 looking for driver at 3600\n",
      "18 looking for driver at 3600\n",
      "17 looking for driver at 3600\n",
      "16 looking for driver at 3600\n",
      "20 looking for driver at 3650\n",
      "19 looking for driver at 3650\n",
      "18 looking for driver at 3650\n",
      "17 looking for driver at 3650\n",
      "16 looking for driver at 3650\n",
      "20 got 0 at 3650\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[38.,  7.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [42 12] from [ 9 31]\n",
      "driver 0 location updated  to  [ 8 18]\n",
      "Trip distance: 35, time 3688\n",
      "21 looking for driver at 3700\n",
      "19 looking for driver at 3700\n",
      "18 looking for driver at 3700\n",
      "17 looking for driver at 3700\n",
      "16 looking for driver at 3700\n",
      "20 finished the trip and released driver 0 at 3723 to pool 1\n",
      "Driver 0 finished trip\n",
      "21 looking for driver at 3750\n",
      "19 looking for driver at 3750\n",
      "18 looking for driver at 3750\n",
      "17 looking for driver at 3750\n",
      "16 looking for driver at 3750\n",
      "21 got 0 at 3750\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[11.,  8.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 0 10] from [ 8 18]\n",
      "driver 0 location updated  to  [28 30]\n",
      "Trip distance: 34, time 3761\n",
      "21 finished the trip and released driver 0 at 3795 to pool 4\n",
      "Driver 0 finished trip\n",
      "22 looking for driver at 3800\n",
      "19 looking for driver at 3800\n",
      "18 looking for driver at 3800\n",
      "17 looking for driver at 3800\n",
      "16 looking for driver at 3800\n",
      "22 looking for driver at 3850\n",
      "19 looking for driver at 3850\n",
      "18 looking for driver at 3850\n",
      "17 looking for driver at 3850\n",
      "16 looking for driver at 3850\n",
      "22 got 0 at 3850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[30.,  9.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 2 16] from [28 30]\n",
      "driver 0 location updated  to  [11 28]\n",
      "Trip distance: 15, time 3880\n",
      "22 finished the trip and released driver 0 at 3895 to pool 4\n",
      "Driver 0 finished trip\n",
      "23 looking for driver at 3900\n",
      "19 looking for driver at 3900\n",
      "18 looking for driver at 3900\n",
      "17 looking for driver at 3900\n",
      "16 was cancelled!\n",
      "23 looking for driver at 3950\n",
      "19 looking for driver at 3950\n",
      "18 looking for driver at 3950\n",
      "17 was cancelled!\n",
      "23 got 0 at 3950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[29., 10.,  0., 13.]], dtype=float32)>)\n",
      "23 looking for driver at 3950\n",
      "23 looking for driver at 4000\n",
      "19 looking for driver at 4000\n",
      "18 looking for driver at 4000\n",
      "23 looking for driver at 4050\n",
      "19 looking for driver at 4050\n",
      "18 looking for driver at 4050\n",
      "24 looking for driver at 4100\n",
      "23 looking for driver at 4100\n",
      "19 looking for driver at 4100\n",
      "18 looking for driver at 4100\n",
      "24 looking for driver at 4150\n",
      "23 looking for driver at 4150\n",
      "19 looking for driver at 4150\n",
      "18 looking for driver at 4150\n",
      "24 looking for driver at 4200\n",
      "23 looking for driver at 4200\n",
      "19 looking for driver at 4200\n",
      "18 was cancelled!\n",
      "24 got 0 at 4200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[44., 10.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [47  2] from [11 28]\n",
      "driver 0 location updated  to  [26  0]\n",
      "Trip distance: 21, time 4244\n",
      "25 looking for driver at 4250\n",
      "23 looking for driver at 4250\n",
      "19 looking for driver at 4250\n",
      "24 finished the trip and released driver 0 at 4265 to pool 3\n",
      "Driver 0 finished trip\n",
      "25 got 0 at 4265\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 1., 11.,  0., 13.]], dtype=float32)>)\n",
      "25 looking for driver at 4265\n",
      "25 looking for driver at 4300\n",
      "23 looking for driver at 4300\n",
      "19 looking for driver at 4300\n",
      "25 looking for driver at 4350\n",
      "23 looking for driver at 4350\n",
      "19 looking for driver at 4350\n",
      "25 looking for driver at 4400\n",
      "23 looking for driver at 4400\n",
      "19 was cancelled!\n",
      "26 looking for driver at 4450\n",
      "25 looking for driver at 4450\n",
      "23 looking for driver at 4450\n",
      "26 looking for driver at 4500\n",
      "25 looking for driver at 4500\n",
      "23 looking for driver at 4500\n",
      "26 got 0 at 4500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 11.,  0., 13.]], dtype=float32)>)\n",
      "26 looking for driver at 4500\n",
      "26 looking for driver at 4550\n",
      "25 looking for driver at 4550\n",
      "23 looking for driver at 4550\n",
      "26 looking for driver at 4600\n",
      "25 looking for driver at 4600\n",
      "23 looking for driver at 4600\n",
      "26 looking for driver at 4650\n",
      "25 looking for driver at 4650\n",
      "23 looking for driver at 4650\n",
      "27 looking for driver at 4700\n",
      "26 looking for driver at 4700\n",
      "25 looking for driver at 4700\n",
      "23 looking for driver at 4700\n",
      "27 looking for driver at 4750\n",
      "26 looking for driver at 4750\n",
      "25 looking for driver at 4750\n",
      "23 looking for driver at 4750\n",
      "27 looking for driver at 4800\n",
      "26 looking for driver at 4800\n",
      "25 looking for driver at 4800\n",
      "23 looking for driver at 4800\n",
      "27 got 0 at 4800\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[38., 11.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 2 30] from [26  0]\n",
      "driver 0 location updated  to  [56 29]\n",
      "Trip distance: 54, time 4838\n",
      "28 looking for driver at 4850\n",
      "26 looking for driver at 4850\n",
      "25 looking for driver at 4850\n",
      "23 looking for driver at 4850\n",
      "27 finished the trip and released driver 0 at 4892 to pool 10\n",
      "Driver 0 finished trip\n",
      "28 looking for driver at 4900\n",
      "26 looking for driver at 4900\n",
      "25 looking for driver at 4900\n",
      "23 looking for driver at 4900\n",
      "28 looking for driver at 4950\n",
      "26 looking for driver at 4950\n",
      "25 looking for driver at 4950\n",
      "23 was cancelled!\n",
      "28 got 0 at 4950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[34., 12.,  0., 13.]], dtype=float32)>)\n",
      "28 looking for driver at 4950\n",
      "28 looking for driver at 5000\n",
      "26 looking for driver at 5000\n",
      "25 looking for driver at 5000\n",
      "29 looking for driver at 5050\n",
      "28 looking for driver at 5050\n",
      "26 looking for driver at 5050\n",
      "25 looking for driver at 5050\n",
      "30 looking for driver at 5100\n",
      "29 looking for driver at 5100\n",
      "28 looking for driver at 5100\n",
      "26 looking for driver at 5100\n",
      "25 looking for driver at 5100\n",
      "30 got 0 at 5100\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[17., 12.,  0., 13.]], dtype=float32)>)\n",
      "30 looking for driver at 5100\n",
      "29 got 0 at 5100\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[22., 12.,  0., 13.]], dtype=float32)>)\n",
      "29 looking for driver at 5100\n",
      "30 looking for driver at 5150\n",
      "29 looking for driver at 5150\n",
      "28 looking for driver at 5150\n",
      "26 looking for driver at 5150\n",
      "25 looking for driver at 5150\n",
      "30 looking for driver at 5200\n",
      "29 looking for driver at 5200\n",
      "28 looking for driver at 5200\n",
      "26 looking for driver at 5200\n",
      "25 looking for driver at 5200\n",
      "30 looking for driver at 5250\n",
      "29 looking for driver at 5250\n",
      "28 looking for driver at 5250\n",
      "26 looking for driver at 5250\n",
      "25 looking for driver at 5250\n",
      "30 looking for driver at 5300\n",
      "29 looking for driver at 5300\n",
      "28 looking for driver at 5300\n",
      "26 looking for driver at 5300\n",
      "25 was cancelled!\n",
      "31 looking for driver at 5350\n",
      "30 looking for driver at 5350\n",
      "29 looking for driver at 5350\n",
      "28 looking for driver at 5350\n",
      "26 looking for driver at 5350\n",
      "31 looking for driver at 5400\n",
      "30 looking for driver at 5400\n",
      "29 looking for driver at 5400\n",
      "28 looking for driver at 5400\n",
      "26 looking for driver at 5400\n",
      "31 got 0 at 5400\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[27., 12.,  0., 13.]], dtype=float32)>)\n",
      "31 looking for driver at 5400\n",
      "31 looking for driver at 5450\n",
      "30 looking for driver at 5450\n",
      "29 looking for driver at 5450\n",
      "28 looking for driver at 5450\n",
      "26 looking for driver at 5450\n",
      "31 looking for driver at 5500\n",
      "30 looking for driver at 5500\n",
      "29 looking for driver at 5500\n",
      "28 looking for driver at 5500\n",
      "26 was cancelled!\n",
      "31 looking for driver at 5550\n",
      "30 looking for driver at 5550\n",
      "29 looking for driver at 5550\n",
      "28 looking for driver at 5550\n",
      "31 looking for driver at 5600\n",
      "30 looking for driver at 5600\n",
      "29 looking for driver at 5600\n",
      "28 looking for driver at 5600\n",
      "32 looking for driver at 5650\n",
      "31 looking for driver at 5650\n",
      "30 looking for driver at 5650\n",
      "29 looking for driver at 5650\n",
      "28 looking for driver at 5650\n",
      "33 looking for driver at 5700\n",
      "32 looking for driver at 5700\n",
      "31 looking for driver at 5700\n",
      "30 looking for driver at 5700\n",
      "29 looking for driver at 5700\n",
      "28 looking for driver at 5700\n",
      "33 looking for driver at 5750\n",
      "32 looking for driver at 5750\n",
      "31 looking for driver at 5750\n",
      "30 looking for driver at 5750\n",
      "29 looking for driver at 5750\n",
      "28 looking for driver at 5750\n",
      "33 got 0 at 5750\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[19., 12.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [53 10] from [56 29]\n",
      "driver 0 location updated  to  [1 6]\n",
      "driver 0 has achieved his weekly reward\n",
      "Trip distance: 52, time 5769\n",
      "32 looking for driver at 5800\n",
      "31 looking for driver at 5800\n",
      "30 looking for driver at 5800\n",
      "29 looking for driver at 5800\n",
      "28 looking for driver at 5800\n",
      "33 finished the trip and released driver 0 at 5821 to pool 0\n",
      "Driver 0 finished trip\n",
      "32 got 0 at 5821\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[25., 13.,  0., 13.]], dtype=float32)>)\n",
      "32 looking for driver at 5821\n",
      "34 looking for driver at 5850\n",
      "32 looking for driver at 5850\n",
      "31 looking for driver at 5850\n",
      "30 looking for driver at 5850\n",
      "29 looking for driver at 5850\n",
      "28 looking for driver at 5850\n",
      "34 looking for driver at 5900\n",
      "32 looking for driver at 5900\n",
      "31 looking for driver at 5900\n",
      "30 looking for driver at 5900\n",
      "29 looking for driver at 5900\n",
      "28 was cancelled!\n",
      "34 looking for driver at 5950\n",
      "32 looking for driver at 5950\n",
      "31 looking for driver at 5950\n",
      "30 looking for driver at 5950\n",
      "29 looking for driver at 5950\n",
      "34 got 0 at 5950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[32., 13.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [21 31] from [1 6]\n",
      "driver 0 location updated  to  [ 0 22]\n",
      "Trip distance: 23, time 5982\n",
      "32 looking for driver at 6000\n",
      "31 looking for driver at 6000\n",
      "30 looking for driver at 6000\n",
      "29 looking for driver at 6000\n",
      "34 finished the trip and released driver 0 at 6005 to pool 1\n",
      "Driver 0 finished trip\n",
      "32 looking for driver at 6050\n",
      "31 looking for driver at 6050\n",
      "30 looking for driver at 6050\n",
      "29 looking for driver at 6050\n",
      "35 looking for driver at 6100\n",
      "32 looking for driver at 6100\n",
      "31 looking for driver at 6100\n",
      "30 looking for driver at 6100\n",
      "29 was cancelled!\n",
      "35 looking for driver at 6150\n",
      "32 looking for driver at 6150\n",
      "31 looking for driver at 6150\n",
      "30 was cancelled!\n",
      "35 looking for driver at 6200\n",
      "32 looking for driver at 6200\n",
      "31 looking for driver at 6200\n",
      "35 looking for driver at 6250\n",
      "32 looking for driver at 6250\n",
      "31 looking for driver at 6250\n",
      "35 got 0 at 6250\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[43., 14.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [39 39] from [ 0 22]\n",
      "driver 0 location updated  to  [52 36]\n",
      "Trip distance: 13, time 6293\n",
      "32 looking for driver at 6300\n",
      "31 looking for driver at 6300\n",
      "35 finished the trip and released driver 0 at 6306 to pool 11\n",
      "Driver 0 finished trip\n",
      "36 looking for driver at 6350\n",
      "32 looking for driver at 6350\n",
      "31 looking for driver at 6350\n",
      "36 looking for driver at 6400\n",
      "32 looking for driver at 6400\n",
      "31 was cancelled!\n",
      "36 looking for driver at 6450\n",
      "32 looking for driver at 6450\n",
      "36 looking for driver at 6500\n",
      "32 looking for driver at 6500\n",
      "36 got 0 at 6500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[39., 15.,  0., 13.]], dtype=float32)>)\n",
      "36 looking for driver at 6500\n",
      "36 looking for driver at 6550\n",
      "32 looking for driver at 6550\n",
      "37 looking for driver at 6600\n",
      "36 looking for driver at 6600\n",
      "32 looking for driver at 6600\n",
      "37 got 0 at 6600\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 3., 15.,  0., 13.]], dtype=float32)>)\n",
      "37 looking for driver at 6600\n",
      "37 looking for driver at 6650\n",
      "36 looking for driver at 6650\n",
      "32 looking for driver at 6650\n",
      "37 looking for driver at 6700\n",
      "36 looking for driver at 6700\n",
      "32 was cancelled!\n",
      "38 looking for driver at 6750\n",
      "37 looking for driver at 6750\n",
      "36 looking for driver at 6750\n",
      "38 looking for driver at 6800\n",
      "37 looking for driver at 6800\n",
      "36 looking for driver at 6800\n",
      "39 looking for driver at 6850\n",
      "38 looking for driver at 6850\n",
      "37 looking for driver at 6850\n",
      "36 looking for driver at 6850\n",
      "39 got 0 at 6850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 9., 15.,  0., 13.]], dtype=float32)>)\n",
      "39 looking for driver at 6850\n",
      "38 got 0 at 6850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[21., 15.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [37 22] from [52 36]\n",
      "driver 0 location updated  to  [30 38]\n",
      "Trip distance: 17, time 6871\n",
      "38 finished the trip and released driver 0 at 6888 to pool 5\n",
      "Driver 0 finished trip\n",
      "39 looking for driver at 6900\n",
      "37 looking for driver at 6900\n",
      "36 looking for driver at 6900\n",
      "39 looking for driver at 6950\n",
      "37 looking for driver at 6950\n",
      "36 looking for driver at 6950\n",
      "40 looking for driver at 7000\n",
      "39 looking for driver at 7000\n",
      "37 looking for driver at 7000\n",
      "36 looking for driver at 7000\n",
      "40 got 0 at 7000\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[19., 16.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [11 39] from [30 38]\n",
      "driver 0 location updated  to  [32 20]\n",
      "Trip distance: 28, time 7019\n",
      "40 finished the trip and released driver 0 at 7047 to pool 7\n",
      "Driver 0 finished trip\n",
      "39 looking for driver at 7050\n",
      "37 looking for driver at 7050\n",
      "36 looking for driver at 7050\n",
      "39 looking for driver at 7100\n",
      "37 looking for driver at 7100\n",
      "36 looking for driver at 7100\n",
      "39 looking for driver at 7150\n",
      "37 looking for driver at 7150\n",
      "36 looking for driver at 7150\n",
      "39 looking for driver at 7200\n",
      "37 looking for driver at 7200\n",
      "36 looking for driver at 7200\n",
      "41 looking for driver at 7250\n",
      "39 looking for driver at 7250\n",
      "37 looking for driver at 7250\n",
      "36 looking for driver at 7250\n",
      "41 looking for driver at 7300\n",
      "39 looking for driver at 7300\n",
      "37 looking for driver at 7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 looking for driver at 7300\n",
      "41 got 0 at 7300\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[11., 17.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [28 30] from [32 20]\n",
      "driver 0 location updated  to  [31  0]\n",
      "Trip distance: 30, time 7311\n",
      "41 finished the trip and released driver 0 at 7341 to pool 6\n",
      "Driver 0 finished trip\n",
      "39 looking for driver at 7350\n",
      "37 looking for driver at 7350\n",
      "36 looking for driver at 7350\n",
      "39 looking for driver at 7400\n",
      "37 looking for driver at 7400\n",
      "36 was cancelled!\n",
      "39 looking for driver at 7450\n",
      "37 looking for driver at 7450\n",
      "39 looking for driver at 7500\n",
      "37 looking for driver at 7500\n",
      "42 looking for driver at 7550\n",
      "39 looking for driver at 7550\n",
      "37 looking for driver at 7550\n",
      "43 looking for driver at 7600\n",
      "42 looking for driver at 7600\n",
      "39 looking for driver at 7600\n",
      "37 looking for driver at 7600\n",
      "42 got 0 at 7600\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[25., 18.,  0., 13.]], dtype=float32)>)\n",
      "42 looking for driver at 7600\n",
      "43 looking for driver at 7650\n",
      "42 looking for driver at 7650\n",
      "39 looking for driver at 7650\n",
      "37 was cancelled!\n",
      "43 got 0 at 7650\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[26., 18.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [57  2] from [31  0]\n",
      "driver 0 location updated  to  [45 13]\n",
      "Trip distance: 16, time 7676\n",
      "43 finished the trip and released driver 0 at 7692 to pool 7\n",
      "Driver 0 finished trip\n",
      "42 looking for driver at 7700\n",
      "39 looking for driver at 7700\n",
      "42 looking for driver at 7750\n",
      "39 looking for driver at 7750\n",
      "42 looking for driver at 7800\n",
      "39 looking for driver at 7800\n",
      "44 looking for driver at 7850\n",
      "42 looking for driver at 7850\n",
      "39 looking for driver at 7850\n",
      "44 got 0 at 7850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 19.,  0., 13.]], dtype=float32)>)\n",
      "44 looking for driver at 7850\n",
      "44 looking for driver at 7900\n",
      "42 looking for driver at 7900\n",
      "39 was cancelled!\n",
      "45 looking for driver at 7950\n",
      "44 looking for driver at 7950\n",
      "42 looking for driver at 7950\n",
      "46 looking for driver at 8000\n",
      "45 looking for driver at 8000\n",
      "44 looking for driver at 8000\n",
      "42 looking for driver at 8000\n",
      "45 got 0 at 8000\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[26., 19.,  0., 13.]], dtype=float32)>)\n",
      "45 looking for driver at 8000\n",
      "46 looking for driver at 8050\n",
      "45 looking for driver at 8050\n",
      "44 looking for driver at 8050\n",
      "42 looking for driver at 8050\n",
      "47 looking for driver at 8100\n",
      "46 looking for driver at 8100\n",
      "45 looking for driver at 8100\n",
      "44 looking for driver at 8100\n",
      "42 looking for driver at 8100\n",
      "46 got 0 at 8100\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[43., 19.,  0., 13.]], dtype=float32)>)\n",
      "46 looking for driver at 8100\n",
      "47 looking for driver at 8150\n",
      "46 looking for driver at 8150\n",
      "45 looking for driver at 8150\n",
      "44 looking for driver at 8150\n",
      "42 looking for driver at 8150\n",
      "47 got 0 at 8150\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[26., 19.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [40 39] from [45 13]\n",
      "driver 0 location updated  to  [54 13]\n",
      "Trip distance: 30, time 8176\n",
      "48 looking for driver at 8200\n",
      "46 looking for driver at 8200\n",
      "45 looking for driver at 8200\n",
      "44 looking for driver at 8200\n",
      "42 looking for driver at 8200\n",
      "47 finished the trip and released driver 0 at 8206 to pool 10\n",
      "Driver 0 finished trip\n",
      "48 looking for driver at 8250\n",
      "46 looking for driver at 8250\n",
      "45 looking for driver at 8250\n",
      "44 looking for driver at 8250\n",
      "42 looking for driver at 8250\n",
      "48 looking for driver at 8300\n",
      "46 looking for driver at 8300\n",
      "45 looking for driver at 8300\n",
      "44 looking for driver at 8300\n",
      "42 looking for driver at 8300\n",
      "48 looking for driver at 8350\n",
      "46 looking for driver at 8350\n",
      "45 looking for driver at 8350\n",
      "44 looking for driver at 8350\n",
      "42 looking for driver at 8350\n",
      "48 got 0 at 8350\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[43., 20.,  0., 13.]], dtype=float32)>)\n",
      "48 looking for driver at 8350\n",
      "48 looking for driver at 8400\n",
      "46 looking for driver at 8400\n",
      "45 looking for driver at 8400\n",
      "44 looking for driver at 8400\n",
      "42 looking for driver at 8400\n",
      "49 looking for driver at 8450\n",
      "48 looking for driver at 8450\n",
      "46 looking for driver at 8450\n",
      "45 looking for driver at 8450\n",
      "44 looking for driver at 8450\n",
      "42 looking for driver at 8450\n",
      "49 looking for driver at 8500\n",
      "48 looking for driver at 8500\n",
      "46 looking for driver at 8500\n",
      "45 looking for driver at 8500\n",
      "44 looking for driver at 8500\n",
      "42 looking for driver at 8500\n",
      "49 got 0 at 8500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[17., 20.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [39 21] from [54 13]\n",
      "driver 0 location updated  to  [51 15]\n",
      "Trip distance: 13, time 8517\n",
      "49 finished the trip and released driver 0 at 8530 to pool 10\n",
      "Driver 0 finished trip\n",
      "48 looking for driver at 8550\n",
      "46 looking for driver at 8550\n",
      "45 looking for driver at 8550\n",
      "44 looking for driver at 8550\n",
      "42 looking for driver at 8550\n",
      "48 looking for driver at 8600\n",
      "46 looking for driver at 8600\n",
      "45 looking for driver at 8600\n",
      "44 looking for driver at 8600\n",
      "42 was cancelled!\n",
      "50 looking for driver at 8650\n",
      "48 looking for driver at 8650\n",
      "46 looking for driver at 8650\n",
      "45 looking for driver at 8650\n",
      "44 looking for driver at 8650\n",
      "50 looking for driver at 8700\n",
      "48 looking for driver at 8700\n",
      "46 looking for driver at 8700\n",
      "45 looking for driver at 8700\n",
      "44 looking for driver at 8700\n",
      "50 looking for driver at 8750\n",
      "48 looking for driver at 8750\n",
      "46 looking for driver at 8750\n",
      "45 looking for driver at 8750\n",
      "44 looking for driver at 8750\n",
      "50 looking for driver at 8800\n",
      "48 looking for driver at 8800\n",
      "46 looking for driver at 8800\n",
      "45 looking for driver at 8800\n",
      "44 looking for driver at 8800\n",
      "50 looking for driver at 8850\n",
      "48 looking for driver at 8850\n",
      "46 looking for driver at 8850\n",
      "45 looking for driver at 8850\n",
      "44 looking for driver at 8850\n",
      "50 got 0 at 8850\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[52., 21.,  0., 13.]], dtype=float32)>)\n",
      "50 looking for driver at 8850\n",
      "51 looking for driver at 8900\n",
      "50 looking for driver at 8900\n",
      "48 looking for driver at 8900\n",
      "46 looking for driver at 8900\n",
      "45 looking for driver at 8900\n",
      "44 was cancelled!\n",
      "51 looking for driver at 8950\n",
      "50 looking for driver at 8950\n",
      "48 looking for driver at 8950\n",
      "46 looking for driver at 8950\n",
      "45 looking for driver at 8950\n",
      "51 got 0 at 8950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 5., 21.,  0., 13.]], dtype=float32)>)\n",
      "51 looking for driver at 8950\n",
      "51 looking for driver at 9000\n",
      "50 looking for driver at 9000\n",
      "48 looking for driver at 9000\n",
      "46 looking for driver at 9000\n",
      "45 was cancelled!\n",
      "51 looking for driver at 9050\n",
      "50 looking for driver at 9050\n",
      "48 looking for driver at 9050\n",
      "46 was cancelled!\n",
      "52 looking for driver at 9100\n",
      "51 looking for driver at 9100\n",
      "50 looking for driver at 9100\n",
      "48 looking for driver at 9100\n",
      "53 looking for driver at 9150\n",
      "52 looking for driver at 9150\n",
      "51 looking for driver at 9150\n",
      "50 looking for driver at 9150\n",
      "48 looking for driver at 9150\n",
      "52 got 0 at 9150\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 21.,  0., 13.]], dtype=float32)>)\n",
      "52 looking for driver at 9150\n",
      "53 looking for driver at 9200\n",
      "52 looking for driver at 9200\n",
      "51 looking for driver at 9200\n",
      "50 looking for driver at 9200\n",
      "48 looking for driver at 9200\n",
      "53 got 0 at 9200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 8., 21.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [57  9] from [51 15]\n",
      "driver 0 location updated  to  [21  2]\n",
      "Trip distance: 37, time 9208\n",
      "53 finished the trip and released driver 0 at 9245 to pool 3\n",
      "Driver 0 finished trip\n",
      "52 looking for driver at 9250\n",
      "51 looking for driver at 9250\n",
      "50 looking for driver at 9250\n",
      "48 was cancelled!\n",
      "52 looking for driver at 9300\n",
      "51 looking for driver at 9300\n",
      "50 looking for driver at 9300\n",
      "52 looking for driver at 9350\n",
      "51 looking for driver at 9350\n",
      "50 looking for driver at 9350\n",
      "52 looking for driver at 9400\n",
      "51 looking for driver at 9400\n",
      "50 looking for driver at 9400\n",
      "54 looking for driver at 9450\n",
      "52 looking for driver at 9450\n",
      "51 looking for driver at 9450\n",
      "50 looking for driver at 9450\n",
      "54 looking for driver at 9500\n",
      "52 looking for driver at 9500\n",
      "51 looking for driver at 9500\n",
      "50 looking for driver at 9500\n",
      "54 got 0 at 9500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[23., 22.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [44  2] from [21  2]\n",
      "driver 0 location updated  to  [30 20]\n",
      "Trip distance: 23, time 9523\n",
      "54 finished the trip and released driver 0 at 9546 to pool 4\n",
      "Driver 0 finished trip\n",
      "55 looking for driver at 9550\n",
      "52 looking for driver at 9550\n",
      "51 looking for driver at 9550\n",
      "50 looking for driver at 9550\n",
      "55 looking for driver at 9600\n",
      "52 looking for driver at 9600\n",
      "51 looking for driver at 9600\n",
      "50 looking for driver at 9600\n",
      "55 got 0 at 9600\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[27., 23.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [11 39] from [30 20]\n",
      "driver 0 location updated  to  [12 12]\n",
      "Trip distance: 27, time 9627\n",
      "56 looking for driver at 9650\n",
      "52 looking for driver at 9650\n",
      "51 looking for driver at 9650\n",
      "50 looking for driver at 9650\n",
      "55 finished the trip and released driver 0 at 9654 to pool 4\n",
      "Driver 0 finished trip\n",
      "56 got 0 at 9654\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[16., 24.,  0., 13.]], dtype=float32)>)\n",
      "56 looking for driver at 9654\n",
      "57 looking for driver at 9700\n",
      "56 looking for driver at 9700\n",
      "52 looking for driver at 9700\n",
      "51 looking for driver at 9700\n",
      "50 was cancelled!\n",
      "57 looking for driver at 9750\n",
      "56 looking for driver at 9750\n",
      "52 looking for driver at 9750\n",
      "51 looking for driver at 9750\n",
      "57 got 0 at 9750\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[26., 24.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 5 37] from [12 12]\n",
      "driver 0 location updated  to  [ 9 20]\n",
      "Trip distance: 17, time 9776\n",
      "57 finished the trip and released driver 0 at 9793 to pool 1\n",
      "Driver 0 finished trip\n",
      "58 looking for driver at 9800\n",
      "56 looking for driver at 9800\n",
      "52 looking for driver at 9800\n",
      "51 looking for driver at 9800\n",
      "58 looking for driver at 9850\n",
      "56 looking for driver at 9850\n",
      "52 looking for driver at 9850\n",
      "51 looking for driver at 9850\n",
      "58 looking for driver at 9900\n",
      "56 looking for driver at 9900\n",
      "52 looking for driver at 9900\n",
      "51 looking for driver at 9900\n",
      "58 looking for driver at 9950\n",
      "56 looking for driver at 9950\n",
      "52 looking for driver at 9950\n",
      "51 was cancelled!\n",
      "58 got 0 at 9950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[43., 25.,  0., 13.]], dtype=float32)>)\n",
      "58 looking for driver at 9950\n",
      "59 looking for driver at 10000\n",
      "58 looking for driver at 10000\n",
      "56 looking for driver at 10000\n",
      "52 looking for driver at 10000\n",
      "59 looking for driver at 10050\n",
      "58 looking for driver at 10050\n",
      "56 looking for driver at 10050\n",
      "52 looking for driver at 10050\n",
      "59 got 0 at 10050\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 25.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [25 12] from [ 9 20]\n",
      "driver 0 location updated  to  [ 7 24]\n",
      "Trip distance: 22, time 10068\n",
      "59 finished the trip and released driver 0 at 10090 to pool 1\n",
      "Driver 0 finished trip\n",
      "58 looking for driver at 10100\n",
      "56 looking for driver at 10100\n",
      "52 looking for driver at 10100\n",
      "58 looking for driver at 10150\n",
      "56 looking for driver at 10150\n",
      "52 was cancelled!\n",
      "58 looking for driver at 10200\n",
      "56 looking for driver at 10200\n",
      "58 looking for driver at 10250\n",
      "56 looking for driver at 10250\n",
      "60 looking for driver at 10300\n",
      "58 looking for driver at 10300\n",
      "56 looking for driver at 10300\n",
      "60 looking for driver at 10350\n",
      "58 looking for driver at 10350\n",
      "56 looking for driver at 10350\n",
      "61 looking for driver at 10400\n",
      "60 looking for driver at 10400\n",
      "58 looking for driver at 10400\n",
      "56 looking for driver at 10400\n",
      "60 got 0 at 10400\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[34., 26.,  0., 13.]], dtype=float32)>)\n",
      "60 looking for driver at 10400\n",
      "61 looking for driver at 10450\n",
      "60 looking for driver at 10450\n",
      "58 looking for driver at 10450\n",
      "56 looking for driver at 10450\n",
      "61 got 0 at 10450\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 9., 26.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [16 22] from [ 7 24]\n",
      "driver 0 location updated  to  [55  9]\n",
      "Trip distance: 41, time 10459\n",
      "60 looking for driver at 10500\n",
      "58 looking for driver at 10500\n",
      "56 looking for driver at 10500\n",
      "61 finished the trip and released driver 0 at 10500 to pool 9\n",
      "Driver 0 finished trip\n",
      "62 looking for driver at 10550\n",
      "60 looking for driver at 10550\n",
      "58 looking for driver at 10550\n",
      "56 looking for driver at 10550\n",
      "62 got 0 at 10550\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 6., 27.,  0., 13.]], dtype=float32)>)\n",
      "62 looking for driver at 10550\n",
      "62 looking for driver at 10600\n",
      "60 looking for driver at 10600\n",
      "58 looking for driver at 10600\n",
      "56 looking for driver at 10600\n",
      "62 looking for driver at 10650\n",
      "60 looking for driver at 10650\n",
      "58 looking for driver at 10650\n",
      "56 looking for driver at 10650\n",
      "62 looking for driver at 10700\n",
      "60 looking for driver at 10700\n",
      "58 looking for driver at 10700\n",
      "56 was cancelled!\n",
      "62 looking for driver at 10750\n",
      "60 looking for driver at 10750\n",
      "58 looking for driver at 10750\n",
      "62 looking for driver at 10800\n",
      "60 looking for driver at 10800\n",
      "58 looking for driver at 10800\n",
      "63 looking for driver at 10850\n",
      "62 looking for driver at 10850\n",
      "60 looking for driver at 10850\n",
      "58 was cancelled!\n",
      "63 looking for driver at 10900\n",
      "62 looking for driver at 10900\n",
      "60 looking for driver at 10900\n",
      "63 looking for driver at 10950\n",
      "62 looking for driver at 10950\n",
      "60 looking for driver at 10950\n",
      "63 looking for driver at 11000\n",
      "62 looking for driver at 11000\n",
      "60 looking for driver at 11000\n",
      "63 got 0 at 11000\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[44., 27.,  0., 13.]], dtype=float32)>)\n",
      "63 looking for driver at 11000\n",
      "64 looking for driver at 11050\n",
      "63 looking for driver at 11050\n",
      "62 looking for driver at 11050\n",
      "60 looking for driver at 11050\n",
      "65 looking for driver at 11100\n",
      "64 looking for driver at 11100\n",
      "63 looking for driver at 11100\n",
      "62 looking for driver at 11100\n",
      "60 looking for driver at 11100\n",
      "65 looking for driver at 11150\n",
      "64 looking for driver at 11150\n",
      "63 looking for driver at 11150\n",
      "62 looking for driver at 11150\n",
      "60 looking for driver at 11150\n",
      "65 looking for driver at 11200\n",
      "64 looking for driver at 11200\n",
      "63 looking for driver at 11200\n",
      "62 looking for driver at 11200\n",
      "60 looking for driver at 11200\n",
      "65 got 0 at 11200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[26., 27.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [37 28] from [55  9]\n",
      "driver 0 location updated  to  [ 3 39]\n",
      "Trip distance: 36, time 11226\n",
      "64 looking for driver at 11250\n",
      "63 looking for driver at 11250\n",
      "62 looking for driver at 11250\n",
      "60 looking for driver at 11250\n",
      "65 finished the trip and released driver 0 at 11262 to pool 2\n",
      "Driver 0 finished trip\n",
      "64 got 0 at 11262\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[40., 28.,  0., 13.]], dtype=float32)>)\n",
      "64 looking for driver at 11262\n",
      "66 looking for driver at 11300\n",
      "64 looking for driver at 11300\n",
      "63 looking for driver at 11300\n",
      "62 looking for driver at 11300\n",
      "60 looking for driver at 11300\n",
      "67 looking for driver at 11350\n",
      "66 looking for driver at 11350\n",
      "64 looking for driver at 11350\n",
      "63 looking for driver at 11350\n",
      "62 looking for driver at 11350\n",
      "60 was cancelled!\n",
      "68 looking for driver at 11400\n",
      "67 looking for driver at 11400\n",
      "66 looking for driver at 11400\n",
      "64 looking for driver at 11400\n",
      "63 looking for driver at 11400\n",
      "62 looking for driver at 11400\n",
      "66 got 0 at 11400\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[33., 28.,  0., 13.]], dtype=float32)>)\n",
      "66 looking for driver at 11400\n",
      "68 looking for driver at 11450\n",
      "67 looking for driver at 11450\n",
      "66 looking for driver at 11450\n",
      "64 looking for driver at 11450\n",
      "63 looking for driver at 11450\n",
      "62 looking for driver at 11450\n",
      "67 got 0 at 11450\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[28., 28.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [ 4 11] from [ 3 39]\n",
      "driver 0 location updated  to  [50 22]\n",
      "Trip distance: 47, time 11478\n",
      "68 looking for driver at 11500\n",
      "66 looking for driver at 11500\n",
      "64 looking for driver at 11500\n",
      "63 looking for driver at 11500\n",
      "62 looking for driver at 11500\n",
      "67 finished the trip and released driver 0 at 11525 to pool 7\n",
      "Driver 0 finished trip\n",
      "68 got 0 at 11525\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[16., 29.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [52  6] from [50 22]\n",
      "driver 0 location updated  to  [46 11]\n",
      "Trip distance: 8, time 11541\n",
      "68 finished the trip and released driver 0 at 11549 to pool 7\n",
      "Driver 0 finished trip\n",
      "66 looking for driver at 11550\n",
      "64 looking for driver at 11550\n",
      "63 looking for driver at 11550\n",
      "62 looking for driver at 11550\n",
      "69 looking for driver at 11600\n",
      "66 looking for driver at 11600\n",
      "64 looking for driver at 11600\n",
      "63 looking for driver at 11600\n",
      "62 was cancelled!\n",
      "69 looking for driver at 11650\n",
      "66 looking for driver at 11650\n",
      "64 looking for driver at 11650\n",
      "63 looking for driver at 11650\n",
      "69 got 0 at 11650\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[13., 30.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [58 17] from [46 11]\n",
      "driver 0 location updated  to  [7 1]\n",
      "Trip distance: 53, time 11663\n",
      "66 looking for driver at 11700\n",
      "64 looking for driver at 11700\n",
      "63 looking for driver at 11700\n",
      "69 finished the trip and released driver 0 at 11716 to pool 0\n",
      "Driver 0 finished trip\n",
      "66 looking for driver at 11750\n",
      "64 looking for driver at 11750\n",
      "63 looking for driver at 11750\n",
      "66 looking for driver at 11800\n",
      "64 looking for driver at 11800\n",
      "63 looking for driver at 11800\n",
      "70 looking for driver at 11850\n",
      "66 looking for driver at 11850\n",
      "64 looking for driver at 11850\n",
      "63 looking for driver at 11850\n",
      "71 looking for driver at 11900\n",
      "70 looking for driver at 11900\n",
      "66 looking for driver at 11900\n",
      "64 looking for driver at 11900\n",
      "63 was cancelled!\n",
      "71 got 0 at 11900\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 4., 31.,  0., 13.]], dtype=float32)>)\n",
      "71 looking for driver at 11900\n",
      "71 looking for driver at 11950\n",
      "70 looking for driver at 11950\n",
      "66 looking for driver at 11950\n",
      "64 looking for driver at 11950\n",
      "71 looking for driver at 12000\n",
      "70 looking for driver at 12000\n",
      "66 looking for driver at 12000\n",
      "64 looking for driver at 12000\n",
      "71 looking for driver at 12050\n",
      "70 looking for driver at 12050\n",
      "66 looking for driver at 12050\n",
      "64 looking for driver at 12050\n",
      "70 got 0 at 12050\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[51., 31.,  0., 13.]], dtype=float32)>)\n",
      "70 looking for driver at 12050\n",
      "72 looking for driver at 12100\n",
      "71 looking for driver at 12100\n",
      "70 looking for driver at 12100\n",
      "66 looking for driver at 12100\n",
      "64 was cancelled!\n",
      "72 looking for driver at 12150\n",
      "71 looking for driver at 12150\n",
      "70 looking for driver at 12150\n",
      "66 looking for driver at 12150\n",
      "73 looking for driver at 12200\n",
      "72 looking for driver at 12200\n",
      "71 looking for driver at 12200\n",
      "70 looking for driver at 12200\n",
      "66 looking for driver at 12200\n",
      "72 got 0 at 12200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[28., 31.,  0., 13.]], dtype=float32)>)\n",
      "72 looking for driver at 12200\n",
      "73 looking for driver at 12250\n",
      "72 looking for driver at 12250\n",
      "71 looking for driver at 12250\n",
      "70 looking for driver at 12250\n",
      "66 looking for driver at 12250\n",
      "74 looking for driver at 12300\n",
      "73 looking for driver at 12300\n",
      "72 looking for driver at 12300\n",
      "71 looking for driver at 12300\n",
      "70 looking for driver at 12300\n",
      "66 looking for driver at 12300\n",
      "74 looking for driver at 12350\n",
      "73 looking for driver at 12350\n",
      "72 looking for driver at 12350\n",
      "71 looking for driver at 12350\n",
      "70 looking for driver at 12350\n",
      "66 was cancelled!\n",
      "73 got 0 at 12350\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[42., 31.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [38 29] from [7 1]\n",
      "driver 0 location updated  to  [20 21]\n",
      "Trip distance: 20, time 12392\n",
      "74 looking for driver at 12400\n",
      "72 looking for driver at 12400\n",
      "71 looking for driver at 12400\n",
      "70 looking for driver at 12400\n",
      "73 finished the trip and released driver 0 at 12412 to pool 4\n",
      "Driver 0 finished trip\n",
      "74 got 0 at 12412\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[34., 32.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [50 38] from [20 21]\n",
      "driver 0 location updated  to  [37 27]\n",
      "Trip distance: 17, time 12446\n",
      "72 looking for driver at 12450\n",
      "71 looking for driver at 12450\n",
      "70 looking for driver at 12450\n",
      "74 finished the trip and released driver 0 at 12463 to pool 7\n",
      "Driver 0 finished trip\n",
      "72 looking for driver at 12500\n",
      "71 looking for driver at 12500\n",
      "70 looking for driver at 12500\n",
      "72 looking for driver at 12550\n",
      "71 looking for driver at 12550\n",
      "70 looking for driver at 12550\n",
      "75 looking for driver at 12600\n",
      "72 looking for driver at 12600\n",
      "71 looking for driver at 12600\n",
      "70 looking for driver at 12600\n",
      "75 looking for driver at 12650\n",
      "72 looking for driver at 12650\n",
      "71 looking for driver at 12650\n",
      "70 looking for driver at 12650\n",
      "75 got 0 at 12650\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 33.,  0., 13.]], dtype=float32)>)\n",
      "75 looking for driver at 12650\n",
      "75 looking for driver at 12700\n",
      "72 looking for driver at 12700\n",
      "71 looking for driver at 12700\n",
      "70 looking for driver at 12700\n",
      "75 looking for driver at 12750\n",
      "72 looking for driver at 12750\n",
      "71 looking for driver at 12750\n",
      "70 looking for driver at 12750\n",
      "75 looking for driver at 12800\n",
      "72 looking for driver at 12800\n",
      "71 looking for driver at 12800\n",
      "70 looking for driver at 12800\n",
      "75 looking for driver at 12850\n",
      "72 looking for driver at 12850\n",
      "71 looking for driver at 12850\n",
      "70 looking for driver at 12850\n",
      "76 looking for driver at 12900\n",
      "75 looking for driver at 12900\n",
      "72 looking for driver at 12900\n",
      "71 looking for driver at 12900\n",
      "70 was cancelled!\n",
      "76 looking for driver at 12950\n",
      "75 looking for driver at 12950\n",
      "72 looking for driver at 12950\n",
      "71 was cancelled!\n",
      "76 got 0 at 12950\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[22., 33.,  0., 13.]], dtype=float32)>)\n",
      "76 looking for driver at 12950\n",
      "76 looking for driver at 13000\n",
      "75 looking for driver at 13000\n",
      "72 looking for driver at 13000\n",
      "76 looking for driver at 13050\n",
      "75 looking for driver at 13050\n",
      "72 looking for driver at 13050\n",
      "76 looking for driver at 13100\n",
      "75 looking for driver at 13100\n",
      "72 looking for driver at 13100\n",
      "76 looking for driver at 13150\n",
      "75 looking for driver at 13150\n",
      "72 was cancelled!\n",
      "77 looking for driver at 13200\n",
      "76 looking for driver at 13200\n",
      "75 looking for driver at 13200\n",
      "77 got 0 at 13200\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[ 6., 33.,  0., 13.]], dtype=float32)>)\n",
      "77 looking for driver at 13200\n",
      "77 looking for driver at 13250\n",
      "76 looking for driver at 13250\n",
      "75 looking for driver at 13250\n",
      "77 looking for driver at 13300\n",
      "76 looking for driver at 13300\n",
      "75 looking for driver at 13300\n",
      "77 looking for driver at 13350\n",
      "76 looking for driver at 13350\n",
      "75 looking for driver at 13350\n",
      "77 looking for driver at 13400\n",
      "76 looking for driver at 13400\n",
      "75 looking for driver at 13400\n",
      "78 looking for driver at 13450\n",
      "77 looking for driver at 13450\n",
      "76 looking for driver at 13450\n",
      "75 looking for driver at 13450\n",
      "79 looking for driver at 13500\n",
      "78 looking for driver at 13500\n",
      "77 looking for driver at 13500\n",
      "76 looking for driver at 13500\n",
      "75 looking for driver at 13500\n",
      "79 got 0 at 13500\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[11., 33.,  0., 13.]], dtype=float32)>)\n",
      "0 traveling to pickup point, [31 18] from [37 27]\n",
      "driver 0 location updated  to  [39 25]\n",
      "Trip distance: 11, time 13511\n",
      "79 finished the trip and released driver 0 at 13522 to pool 7\n",
      "Driver 0 finished trip\n",
      "78 got 0 at 13522\n",
      "TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[18., 34.,  0., 13.]], dtype=float32)>)\n",
      "78 looking for driver at 13522\n",
      "78 looking for driver at 13550\n",
      "77 looking for driver at 13550\n",
      "76 looking for driver at 13550\n",
      "75 looking for driver at 13550\n",
      "78 looking for driver at 13600\n",
      "77 looking for driver at 13600\n",
      "76 looking for driver at 13600\n",
      "75 looking for driver at 13600\n",
      "78 looking for driver at 13650\n",
      "77 looking for driver at 13650\n",
      "76 looking for driver at 13650\n",
      "75 was cancelled!\n",
      "78 looking for driver at 13700\n",
      "77 looking for driver at 13700\n",
      "76 looking for driver at 13700\n",
      "78 looking for driver at 13750\n",
      "77 looking for driver at 13750\n",
      "76 looking for driver at 13750\n",
      "78 looking for driver at 13800\n",
      "77 looking for driver at 13800\n",
      "76 looking for driver at 13800\n",
      "78 looking for driver at 13850\n",
      "77 looking for driver at 13850\n",
      "76 looking for driver at 13850\n",
      "78 looking for driver at 13900\n",
      "77 looking for driver at 13900\n",
      "76 looking for driver at 13900\n",
      "78 looking for driver at 13950\n",
      "77 looking for driver at 13950\n",
      "76 was cancelled!\n",
      "78 looking for driver at 14000\n",
      "77 looking for driver at 14000\n",
      "78 looking for driver at 14050\n",
      "77 looking for driver at 14050\n",
      "78 looking for driver at 14100\n",
      "77 looking for driver at 14100\n",
      "78 looking for driver at 14150\n",
      "77 looking for driver at 14150\n",
      "78 looking for driver at 14200\n",
      "77 looking for driver at 14200\n",
      "78 looking for driver at 14250\n",
      "77 was cancelled!\n",
      "78 looking for driver at 14300\n",
      "78 looking for driver at 14350\n",
      "78 looking for driver at 14400\n",
      "78 looking for driver at 14450\n",
      "78 was cancelled!\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 completed 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'state': <RideSimulator.State.State at 0x7f7a846f00d0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [10, 0, 0, 13],\n",
       "  'reward': 170},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8c4ea30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [12, 1, 0, 13],\n",
       "  'reward': 110},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c84020a0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [44, 2, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c84024f0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [20, 2, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402550>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [21, 2, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402b50>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [52, 2, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c84022e0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [34, 2, 0, 13],\n",
       "  'reward': 30},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402ee0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [21, 3, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402910>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [16, 3, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8c4ee20>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [21, 3, 0, 13],\n",
       "  'reward': -45},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402d90>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [13, 4, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f7a846f02e0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [17, 4, 0, 13],\n",
       "  'reward': -30},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402b80>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [42, 5, 0, 13],\n",
       "  'reward': -5},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402d00>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [10, 6, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402640>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [17, 6, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402a30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [12, 6, 0, 13],\n",
       "  'reward': 60},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402c10>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [8, 7, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aefa0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [46, 7, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402b20>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [44, 7, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83ae8b0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [14, 7, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402790>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [38, 7, 0, 13],\n",
       "  'reward': -15},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aeb80>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [11, 8, 0, 13],\n",
       "  'reward': 115},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aedf0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [30, 9, 0, 13],\n",
       "  'reward': -75},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aed30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [29, 10, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83ae550>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [44, 10, 0, 13],\n",
       "  'reward': -115},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83ae940>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [1, 11, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83be760>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [18, 11, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402280>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [38, 11, 0, 13],\n",
       "  'reward': 80},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aeee0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [34, 12, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c84026d0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [17, 12, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aea30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [22, 12, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402be0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [27, 12, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83ca160>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [19, 12, 0, 13],\n",
       "  'reward': 665},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bed60>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [25, 13, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bed00>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [32, 13, 0, 13],\n",
       "  'reward': -45},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aedc0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [43, 14, 0, 13],\n",
       "  'reward': -150},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83beca0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [39, 15, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83be910>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [3, 15, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402a90>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [9, 15, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83caac0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [21, 15, 0, 13],\n",
       "  'reward': -20},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bec10>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [19, 16, 0, 13],\n",
       "  'reward': 45},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bebb0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [11, 17, 0, 13],\n",
       "  'reward': 95},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83befd0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [25, 18, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bea30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [26, 18, 0, 13],\n",
       "  'reward': -50},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8402850>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [18, 19, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83cabe0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [26, 19, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83caee0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [43, 19, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b06a0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [26, 19, 0, 13],\n",
       "  'reward': 20},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83cadf0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [43, 20, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0520>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [17, 20, 0, 13],\n",
       "  'reward': -20},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bee80>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [52, 21, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83aed60>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [5, 21, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83ca4f0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [18, 21, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83bee20>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [8, 21, 0, 13],\n",
       "  'reward': 145},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0e20>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [23, 22, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83cac70>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [27, 23, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0c10>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [16, 24, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b03d0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [26, 24, 0, 13],\n",
       "  'reward': -45},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83cad30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [43, 25, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83cadc0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [18, 25, 0, 13],\n",
       "  'reward': 20},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83be880>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [34, 26, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0e80>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [9, 26, 0, 13],\n",
       "  'reward': 160},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0d00>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [6, 27, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0f70>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [44, 27, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0100>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [26, 27, 0, 13],\n",
       "  'reward': 50},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6250>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [40, 28, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6b20>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [33, 28, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6e80>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [28, 28, 0, 13],\n",
       "  'reward': 95},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83615b0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [16, 29, 0, 13],\n",
       "  'reward': -40},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6d60>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [13, 30, 0, 13],\n",
       "  'reward': 200},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6310>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [4, 31, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6d30>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [51, 31, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0760>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [28, 31, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d6ee0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [42, 31, 0, 13],\n",
       "  'reward': -110},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b05b0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [34, 32, 0, 13],\n",
       "  'reward': -85},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83d69a0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [18, 33, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c83b0a90>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [22, 33, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8361bb0>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [6, 33, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8361f70>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=()),\n",
       "  'observation': [11, 33, 0, 13],\n",
       "  'reward': 0},\n",
       " {'state': <RideSimulator.State.State at 0x7f79c8361880>,\n",
       "  'action': PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, state=(), info=()),\n",
       "  'observation': [18, 34, 0, 13],\n",
       "  'reward': 0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r#un_simulation(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ts.transition(np.array([1,2,3,4], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=array(2, dtype=int32), reward=array(0., dtype=float32), discount=array(0., dtype=float32), observation=array([1, 2, 3, 4], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ts.termination(np.array([1,2,3,4], dtype=np.int32), reward=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average return\n",
    "\n",
    "def compute_avg_return(policy, num_episodes=10):\n",
    "    total_reward = 0\n",
    "\n",
    "    for i in range (num_episodes):\n",
    "        #run one episode of simulation and record states\n",
    "        state_list = run_simulation(policy)\n",
    "        states = []\n",
    "        episode_reward = 0\n",
    "\n",
    "        #convert states directly to tf timesteps\n",
    "        for i in range(len(state_list)):\n",
    "            state_tf = ts.TimeStep(tf.constant([1]), tf.constant(state_list[i][\"reward\"], dtype=tf.float32), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "            episode_reward += (states[j].reward)\n",
    "\n",
    "        total_reward += episode_reward\n",
    "\n",
    "    avg_return = total_reward / num_episodes\n",
    "    return avg_return.numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect trajectories\n",
    "\n",
    "def collect_data(num_iterations, policy, replay_buffer):\n",
    "    for i in range (num_iterations):\n",
    "        #run one episode of simulation and record states\n",
    "        state_list = run_simulation(policy)\n",
    "        states = []\n",
    "        actions = []\n",
    "        \n",
    "        #convert states directly to tf timesteps\n",
    "        for i in range(len(state_list)):\n",
    "            #create time step\n",
    "            if i == 0:\n",
    "                #state_tf = ts.restart(np.array(state_list[i][\"observation\"], dtype=np.float32))\n",
    "                state_tf = ts.TimeStep(tf.constant([0]), tf.constant([3.0]), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "                print (state_tf)\n",
    "            elif i < (len(state_list) - 1):\n",
    "                state_tf = ts.TimeStep(tf.constant([1]), tf.constant(state_list[i][\"reward\"], dtype=tf.float32), tf.constant([1.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "                #state_tf = ts.termination(np.array(state_list[i][\"observation\"], dtype=np.float32), reward=state_list[i][\"reward\"])\n",
    "            else:\n",
    "                state_tf = ts.TimeStep(tf.constant([2]), tf.constant(state_list[i][\"reward\"], dtype=tf.float32), tf.constant([0.0]), tf.convert_to_tensor(np.array([state_list[i][\"observation\"]], dtype=np.float32), dtype=tf.float32))\n",
    "\n",
    "            #create action\n",
    "            \"\"\"if state_list[i][\"action\"] == 1:\n",
    "                action = tf.constant([1], dtype=tf.int32)\n",
    "            else:\n",
    "                action = tf.constant([0], dtype=tf.int32)\"\"\"\n",
    "            action = state_list[i][\"action\"]\n",
    "\n",
    "            #print (action)\n",
    "            states.append(state_tf)\n",
    "            actions.append(action)\n",
    "\n",
    "        for j in range(len(states)-1):\n",
    "            present_state = states[j]\n",
    "            next_state = states[j+1]\n",
    "            action = actions[j]\n",
    "            traj = trajectory.from_transition(present_state, action, next_state)\n",
    "            #print(action)\n",
    "            # Add trajectory to the replay buffer\n",
    "            replay_buffer.add_batch(traj)\n",
    "            #print(traj)\n",
    "\n",
    "        \"\"\"\n",
    "        #re-register environemnt with new states\n",
    "        env_name = 'taxi-v'+str(i)\n",
    "        gym.envs.register(\n",
    "             id=env_name,\n",
    "             entry_point='env.taxi:TaxiEnv',\n",
    "             max_episode_steps=1500,\n",
    "             kwargs={'state_dict':state_list},\n",
    "        )\n",
    "\n",
    "        #reload new env\n",
    "        env = suite_gym.load(env_name)\n",
    "        tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "        #reset tf env\n",
    "        time_step = tf_env.reset()\n",
    "\n",
    "        #loop through recorded steps\n",
    "        for step in state_dict:\n",
    "            present_state = tf_env.current_time_step()\n",
    "            action = step.action\n",
    "            new_state = tf_env.step(action)\n",
    "            traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "            replay_buffer.add_batch(traj)\n",
    "        \"\"\"\n",
    "        #print(replay_buffer)\n",
    "#collect_data(num_iterations, policy, replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3628d1a70aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Evaluate the agent's policy once before training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mavg_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_avg_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_eval_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mavg_return\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_env' is not defined"
     ]
    }
   ],
   "source": [
    "#train \n",
    "\n",
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    collect_data(collect_steps_per_iteration, policy, replay_buffer)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)\n",
    "        print(\"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize progress\n",
    "\n",
    "\n",
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startup simulation\n",
    "\n",
    "def simpy_episode(rewards, steps, time_step, tf_env, policy):\n",
    "\n",
    "    TIME_MULTIPLIER = 50\n",
    "    DRIVER_COUNT = 1\n",
    "    TRIP_COUNT = 8000\n",
    "    RUN_TIME = 10000\n",
    "    INTERVAL = 20\n",
    "    # GRID_WIDTH = 3809\n",
    "    # GRID_HEIGHT = 2622\n",
    "    GRID_WIDTH = 60\n",
    "    GRID_HEIGHT = 40\n",
    "    HEX_AREA = 2.6\n",
    "\n",
    "    Env = simpy.Environment()\n",
    "    map_grid = Grid(env=Env, width=GRID_WIDTH, height=GRID_HEIGHT, interval=INTERVAL, num_drivers=DRIVER_COUNT,\n",
    "                    hex_area=HEX_AREA)\n",
    "\n",
    "    taxi_spots = map_grid.taxi_spots\n",
    "    driver_list = create_drivers(Env, DRIVER_COUNT, map_grid)\n",
    "    driver_pools = map_grid.driver_pools\n",
    "\n",
    "    run_simulation(TRIP_COUNT, RUN_TIME, DRIVER_COUNT, TIME_MULTIPLIER, map_grid, taxi_spots, driver_list, driver_pools, Env, rewards, steps, time_step, tf_env, policy)\n",
    "    t_count = 0\n",
    "    for dr in driver_list:\n",
    "        d_t_count = dr.total_trip_count\n",
    "        t_count += d_t_count\n",
    "        print(f\"{dr.id} completed {d_t_count}\")\n",
    "\n",
    "    print(f\"Total trip count: {t_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fa715307c8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "var = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "var[0] = 2\n",
    "print (var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    rewards.append(episode_reward)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#simple episode run - atttempt 1\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    simpy_episode(rewards, step, time_step, tf_env, policy)\n",
    "\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple episode run - atttempt 2\n",
    "\n",
    "#time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    time_step = tf_env.reset()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    simpy_episode(rewards, step, time_step, tf_env, policy)\n",
    "\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple episode run template\n",
    "\"\"\"\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "  episode_reward = 0\n",
    "  episode_steps = 0\n",
    "  while not time_step.is_last():\n",
    "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "  time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
